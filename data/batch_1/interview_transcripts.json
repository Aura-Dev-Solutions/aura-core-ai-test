[
  {
    "interview_id": "INT-001",
    "date": "2024-04-16T19:27:32",
    "participant_id": "P-014",
    "participant_role": "Eng Lead",
    "participant_company_size": "",
    "interviewer": "James Chen",
    "interview_type": "behavioral",
    "product_areas_discussed": [
      "reporting"
    ],
    "transcript": "[00:00:24] James Chen: Walk me through how you typically prepare your weekly or monthly metrics for your team.\n[00:01:22] Participant: Every Monday morning I pull the same set of numbers. Conversion rate, active users, churn for the previous week. The annoying part is that I have to run three separate exports and then manually stitch them together in Google Sheets. There's no way to bundle those into a single scheduled output. My manager wants it in her inbox by 9 AM and sometimes the export takes twenty minutes to generate, so I have to start at like 8:30 and just wait.\n\nParticipant: I realize I'm going on a tangent but this connects to a bigger issue. My previous company was acquired about two years ago and during the integration we had to merge two instances of the same platform. That experience traumatized me so much that I now document every configuration change I make. My colleagues think I'm paranoid but I've already prevented at least two disasters because of my notes.\n[00:05:38] James Chen: Tell me about how you share periodic summaries with leadership and what that process looks like.\n[00:07:51] Participant: It's honestly more manual than it should be. I generate the summary, export it as a PDF, then paste key highlights into a Slack message. Our VP wants the actual attachment in email though, so I also have to send it via email separately. If I could just set it to auto-send to a Slack channel and an email distribution list at the same time, that would save me probably forty-five minutes a week across all the different summaries I manage.\n\n[00:09:46] James Chen: Can you describe a time when you needed to grant someone access to specific data summaries without exposing everything?\n[00:11:34] Participant: We had a board observer who needed to see our top-line growth metrics but absolutely should not have access to individual customer data or revenue breakdowns by segment. There was no way to share just a specific set of charts. It was all or nothing. I ended up creating a separate login with restricted permissions, but even then some of the drill-down links on the charts would take them to pages they weren't supposed to see. It felt really insecure and I flagged it with our security team.\n\n[00:13:59] James Chen: Can you describe a specific situation where the numbers you exported didn't match what you expected?\n[00:15:05] Participant: Yes, this happened in January. Our finance team flagged that the revenue figures I sent them were about 12% lower than what they had in their own system. It turned out the date filter was using UTC but I was looking at data assuming Pacific time. So I was missing almost a full day of transactions on either end. Nobody ever told me the system defaults to UTC. That was a really uncomfortable conversation to have with the CFO.\n\n[00:21:18] James Chen: Tell me about a time when you had to schedule a recurring delivery of data to someone outside your team.\n[00:24:39] Participant: Our client success team asked me to set up a weekly summary of usage metrics that would go directly to three of our enterprise customers. The scheduling part was fine, but I couldn't figure out how to make it send to external email addresses. Internal was no problem, but anything with an outside domain would just silently fail. I opened a support ticket and they told me it was a known limitation. So now I just manually forward it every Friday afternoon, which is not ideal.\n\n[00:28:36] James Chen: Walk me through the last time you tried to customize a chart or visualization for a specific audience.\n[00:29:45] Participant: I was trying to make a funnel chart for our sales leadership meeting about two weeks ago. The default colors were fine but I needed to change the labels to match our internal terminology. There was no way to rename the stages in the chart itself; it just pulled from the underlying field names which are all these cryptic codes from the database. I also wanted to add a benchmark line but that feature apparently only works with bar charts, not funnels.\n\n[00:31:02] James Chen: Tell me about the last time you needed to pull data for a stakeholder presentation.\n[00:34:14] Participant: Oh, that was just last week actually. I needed to put together our quarterly metrics for the board meeting. I spent about three hours trying to get the numbers to line up between what I was seeing on screen and what came out in the export. The PDF kept cutting off the right side of the charts, and when I switched to CSV the date columns were all reformatted. I ended up screenshotting everything which felt really hacky for a board presentation.\n",
    "duration_minutes": 61,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-002",
    "date": "June 2, 2024",
    "participant_id": "P-019",
    "participant_role": "sales lead",
    "participant_company_size": "large enterprise",
    "interviewer": "Laura Martinez",
    "interview_type": "behavioral",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Walk basically me um through what happens when you uh get an email from the yeah system yeah - do you usually act so on it or ignore kind of it?\nParticipant: I'd right say I act on actually maybe 10% of the emails I get from the platform. The problem is signal-to-noise ratio you know I um get about forty system actually emails uh a day and you know maybe four of them require action. The subject lines are actually all the same format so I can't basically visually scan for you know important right ones like They all say something like 'Notification from sort of Platform - Event Update.' No right severity level, no category um no preview of what happened. I've set up Gmail filters I mean to try honestly to sort them kind of but the email format sort of doesn't like give uh me enough metadata kind of to filter effectively.\n\nInterviewer: Tell right me about how sort of you audit who has access to what sort of in you're organization.\nParticipant: We don't have a uh good way to I mean do it honestly. There's no export of 'all users basically and their so permissions' that I can pull. I have uh to go into um each user's profile like individually so to see what they have access to. yeah With 300 users that's obviously not feasible yeah to do regularly. honestly Our security team wants a quarterly access honestly review um and I've told them it would take me you know literally a full yeah week to compile that report manually They I mean were I mean not kind of thrilled to hear that. We've been talking about building a yeah script to pull it via the actually backend but nobody's had I mean time.\n\nInterviewer: Walk me through how your organization manages single sign-on across your tools.\nParticipant: We use um Okta for SSO but basically the SCIM provisioning with this platform honestly has yeah been flaky since day one Users get created in the like system when they're added to the Okta group but their roles don't get synced. So every new person comes in with default I mean permissions and then someone like on my team has basically to manually configure basically their role. We've been yeah told SCIM role mapping is on the roadmap but that was eight months ago. For a company with 300 people and regular turnover, this manual step basically is right a I mean real burden.\n\nInterviewer: Can you describe a um time when permission changes you know propagated in unexpected ways?\nParticipant: I made what I I mean thought um was a simple change to our kind of 'Editor' role to yeah remove the ability to delete records sort of The next morning I had fifteen people so telling me they could no longer create records either Apparently the create and delete permissions were right coupled under a single 'write' so capability. you know You couldn't remove delete without also removing create you know There was no documentation about which permissions were you know bundled together. I had to roll the change back and our users could still delete things, which was honestly the original problem.\n\nInterviewer: Can yeah you describe a time when alert um fatigue led to uh a real actually consequence for yeah your team?\nParticipant: Last September our CI/CD pipeline started sending failure alerts for a flaky test that failed about twelve times like a day. basically After a week, the whole engineering team started ignoring pipeline failure emails Then a legitimate deployment failure happened that like introduced a data corruption bug. Nobody caught it from the alerts because we were all so you know desensitized. The bug was in production for three yeah days sort of before a customer kind of reported data inconsistencies We estimate it affected like about 2 000 records. The root cause wasn't the bug itself, it was the fact that we couldn't so distinguish important failures from I mean noise \n\nInterviewer: Walk me through how like you set up rules for when and how you want to be pinged about changes.\nParticipant: The rule builder is deceptively simple on the sort of surface You pick a trigger event, a condition, and a channel. But the conditions are limited to exact match um comparisons kind of I can't right say right 'alert like me when revenue right drops by more than 10% so compared to the same day last week.' I uh can only say 'alert me uh when revenue is like below X number.' yeah For so a dynamic sort of metric like revenue, like setting basically a static threshold means right I'm constantly adjusting it as we grow. I so also can't combine conditions, like 'revenue drops AND active basically users drops.' Each rule is completely independent.\n\nInterviewer: Tell me about configuring quiet hours or do-not-disturb for non-critical I mean alerts.\nParticipant: There's no quiet hours feature. Period I right get the same volume of non-critical yeah emails at 3 AM as I do at 3 sort of PM. so My phone buzzes with push notifications you know during dinner, during weekends, during vacation The only option is to um completely mute everything which sort of means right I'd also miss critical alerts I've asked for a simple quiet hours setting where only severity-one alerts come through between 10 PM I mean and uh 7 AM. The you know response was that yeah they're working on notification tiers but no timeline was given That was over a year ago \n\nInterviewer: Walk me through how you currently handle setting up permissions for different right roles on you're honestly team \nParticipant: It's incredibly I mean granular which sounds like a good thing but in practice actually its paralyzing. their are over sixty individual permission toggles and basically they're not grouped in any intuitive uh way uh Read access to um the analytics module is so separate from export access which I mean is separate from share access. I spent sort of two hours last week trying to create a 'read-only analyst' actually role and I'm honestly still not confident I like didn't accidentally give actually them delete sort of permissions on something. There's no preview or test um mode \n",
    "duration_minutes": 66,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-003",
    "date": "2024-02-26T20:57:32",
    "participant_id": "P-020",
    "participant_role": "UX Designer",
    "participant_company_size": "large enterprise",
    "interviewer": "Laura Martinez",
    "interview_type": "discovery",
    "product_areas_discussed": [
      "user-management",
      "connectors"
    ],
    "transcript": "Q: Can you describe a specific situation where someone had acce...\nintern saw salary data in HR analytics - marketing dept - mentioned 'interesting numbers' to manager - Marketing Viewer role inherited HR read from parent group - 4 levels deep inheritance - completely opaque - audited every role after\n\nQ: Can you describe the most complicated permissions setup you'...\nCS team needs account-level data isolation - no row-level access by ownership - created separate team per client - 42 enterprise clients = 42 teams - manual moves when reps change assignments - unsustainable\n\nQ: Tell me about a time when a third-party tool changed their i...\nGoogle Sheets API deprecation - no warning not subscribed to notices - daily sync stopped - lost 3 days data no queuing - engineering dropped everything - week to migrate new API version\n\nQ: Walk me through what you do when the connection between two ...\npanic - no good monitoring on connectors - someone notices stale data - scramble to diagnose - expired credential or rate limit or schema change - 4hrs to diagnose - error logs just 'sync failed' no details\n\nQ: Tell me about the last time you needed to onboard a new team...\n3 new engineers last Monday - invite emails fine - couldn't assign team + role same step - 3 separate screens: accounts teams roles - 9 operations for 3 people - January cohort of 15 took entire morning\n\nQ: Walk me through how you currently handle setting up permissi...\n60+ individual permission toggles - not grouped intuitively - read vs export vs share all separate - 2hrs creating read-only analyst role - not confident about accidental delete perms - no preview or test mode\n\nQ: Tell me about the last time you tried to connect a new tool ...\nmonth ago - new PM tool sync with CRM - OAuth fine but field mapping nightmare - custom fields not recognized - workaround fields both sides - 2 weeks to get working - 5% records still don't sync\n\nQ: Can you describe a situation where you needed real-time data...\ninventory + e-commerce need real-time - only 30min batch sync - flash sales oversold products stale stock - Black Friday 200 units oversold - CS refund requests 2 weeks - asking for real-time webhooks 1yr+\n",
    "duration_minutes": 29,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-004",
    "date": "2024-09-20T10:57:13",
    "participant_id": "P-110",
    "participant_role": "Product Designer",
    "participant_company_size": "midsize",
    "interviewer": "David Kim",
    "interview_type": "behavioral",
    "product_areas_discussed": [],
    "transcript": "Q: Walk me through how you typically look things up when you ne...\nglobal lookup bar only account names default - email phone custom fields need advanced mode - separate page 4sec load - pick entity type pick field type query - 4 steps vs Google 1 step - team keeps Google Sheet with frequent records + IDs because faster\n\nQ: Can you describe the most painful handoff between two system...\nZendesk to Jira handoff - CS manually creates Jira ticket - copies context screenshots tags team - no auto linking - engineering fixes but CS doesn't know - things fall through constantly\n\nQ: Walk me through how data currently flows between the differe...\nSalesforce source of truth - pushes to HubSpot (15min sync) + internal tool (hourly sync) - sales rep updates lag to marketing - campaigns sent to churned customers\n\nQ: Can you describe the most frustrating experience you've had ...\nspecific support conversation billing dispute 3 months ago - system doesn't index conversation content - searching customer name only shows account - go into account activity timeline - no date range filter on timeline - scroll 3 months visually scan - 25 min - intern faster with Ctrl+F on spreadsheet\n\nQ: Tell me about how your team decided which external tools to ...\n6 month ago audit - 14 tools only 4 native connectors - rest Zapier custom scripts copy-paste - every team thought theirs most critical - $40K middleware licensing\n\nQ: Tell me about the last time you tried to connect a new tool ...\nmonth ago - new PM tool sync with CRM - OAuth fine but field mapping nightmare - custom fields not recognized - workaround fields both sides - 2 weeks to get working - 5% records still don't sync\n\nQ: Can you describe a specific situation where the results you ...\nsearched 'healthcare' for industry accounts - 500 results word appeared anywhere in any field - meeting notes emails bios everything - not ranked by relevance sorted by creation date - actual accounts on page 3 created years ago - can't search specific field from main bar\n\nQ: Walk me through how you save and reuse frequently needed loo...\nsaved lookups feature basic - saves filter criteria but not column layout sort order grouping - 'At-risk enterprise accounts' opens default columns - manually add health score last activity owner every time - 6 saved lookups each needs 3min column config before useful\n",
    "duration_minutes": 48,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-005",
    "date": "2024-07-14T07:25:48",
    "participant_id": "P-105",
    "participant_role": "Customer Success",
    "participant_company_size": "mid-market",
    "interviewer": "Aisha Patel",
    "interview_type": "usability",
    "product_areas_discussed": [
      "email alerts",
      "API",
      "data-import"
    ],
    "transcript": "Q: Tell me about a time when the column headers in your file di...\npartner data different column names - Company Name vs Organization vs org_name - auto-mapping confused - mapped Phone Number to Fax field - didn't catch until after upload - 3K records phone in fax field - manual mapping dropdown 200+ system fields\n\nQ: Can you describe the most frustrating experience you've had ...\nhistorical event data 90 days - endpoint default 30 days - docs wrong start_date/end_date actually from/to - response format different >30 days vs recent - different field names different nesting - two separate parsers same data\n\nQ: Tell me about how you deal with files that have special char...\ncheck encoding in text editor before upload - Latin American clients tildes accents enye - upload preview shows correctly but DB corrupts - UTF-8 conversion script before every upload - shouldn't be my job - platform should handle common encodings - 20hrs cleanup time last quarter\n\nQ: Tell me about how your team coordinates around making sure t...\nelaborate Slack channel routing - ops-alerts eng-critical sales-notifications - platform no native channel routing - webhook to Python middleware routes by event type - middleware down = all routing breaks - maintain on personal time not sustainable\n\nQ: Tell me about trying to handle webhooks from the platform....\nwebhook setup easy - retry logic aggressive - non-200 within 5sec retries immediately - 50 retries no backoff - handler slow 10min got 3000 duplicate events - 40 slipped through created duplicate records - building own idempotency layer\n\nQ: Tell me about the last time you missed an important alert th...\nproduction DB 95% capacity - alert configured but never received - sent to decommissioned email DL from 6 months ago - system showed 'delivered' because server accepted - dead mailbox nobody monitoring - caught by developer noticing slow queries\n",
    "duration_minutes": "",
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-006",
    "date": "02/13/2024",
    "participant_id": "",
    "participant_role": "Sales Dir",
    "participant_company_size": "201-500",
    "interviewer": "James Chen",
    "interview_type": "usability",
    "product_areas_discussed": [],
    "transcript": "Q: Tell me about the last time you tried to connect a new tool ...\nmonth ago - new PM tool sync with CRM - OAuth fine but field mapping nightmare - custom fields not recognized - workaround fields both sides - 2 weeks to get working - 5% records still don't sync\n\nQ: Tell me about configuring quiet hours or do-not-disturb for ...\nno quiet hours feature - same volume 3AM as 3PM - push notifs during dinner weekends vacation - only option complete mute loses critical alerts - asked for quiet hours severity-one only 10PM-7AM - 'working on notification tiers' no timeline - over a year ago\n\nQ: Can you describe the experience of receiving and acting on p...\npush notifications noisy non-actionable - banner 'New activity on Account XYZ' no details - tapping opens home screen not activity - manually find account and activity - half the time someone just viewed record - turned off push entirely - check app manually few times daily\n\n\n[transcript incomplete â€” recording ended early]",
    "duration_minutes": 27,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-007",
    "date": "June 3, 2024",
    "participant_id": "",
    "participant_role": "data analyst",
    "participant_company_size": "201-500",
    "interviewer": "David Kim",
    "interview_type": "feedback",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Can you actually describe the most frustrating right experience you've so had trying to get data actually programmatically?\nParticipant: Trying to get historical kind of event data for you know the last 90 days was a nightmare. The events endpoint only returns the last 30 honestly days sort of by default and the documentation for the date range parameters uh was just wrong It actually said too use 'start_date' and 'end_date' but the honestly actual parameter names were 'from' you know and 'to'. Then when I got the right uh parameters, basically the response format for events older so then 30 days was completely different from recent like events Different field uh names, different nesting honestly structure. I had to write you know two separate parsers I mean for what actually should kind of be actually the same data.\n\nInterviewer: Tell me about trying to do a basically lookup that spans multiple entity types simultaneously \nParticipant: Sometimes I just need to find anything I mean related to a particular keyword across accounts, contacts, tickets, like and notes. The system forces basically you to pick one entity right type at a time. So uh I have to run the same query four sort of separate times: once for accounts, once for contacts, uh once for tickets, once for notes. sort of Each lookup um takes so about ten seconds. sort of There's kind of no unified results page. And the ironic thing is we have so a cross-entity relationship graph in the backend right but the lookup doesn't leverage it right at actually all. I know because I've talked to their right engineering team honestly about it.\n\nInterviewer: Walk me through how you test your calls before deploying them to production.\nParticipant: There's no sandbox environment, um which is a real problem We test against our production instance kind of with a test sort of account. But there's so no way yeah to sort of flag requests actually as test requests so I mean our analytics get polluted kind of with test data. I've like asked about a staging basically environment or honestly at minimum a test kind of mode flag on requests and the response was sort of that it's uh not a priority So we so end up writing cleanup actually scripts that delete test actually data like after our testing basically runs which itself creates more calls actually against our already tight rate actually limits.\n\nInterviewer: Tell me about trying too handle webhooks from the platform.\nParticipant: Setting up kind of webhook sort of receivers was easy enough, sort of but the retry logic is aggressive and like poorly designed. If right our server returns I mean anything other than a so 200 within 5 uh seconds it retries immediately. like And it retries up to 50 times with no backoff. We had an incident where sort of our webhook you know handler was slow for about ten minutes and we received you know over 3,000 duplicate yeah events. Our deduplication logic caught most kind of of kind of them but about 40 right slipped through and created sort of duplicate records in our system. Now we have to build our own idempotency layer.\n\nInterviewer: Tell me sort of about how your team handles finding records that were created you know by someone else.\nParticipant: This comes up basically constantly with our sales yeah team. One rep needs to look at an account honestly that yeah another rep owns. There's no 'created by' or 'owned by' filter in the main honestly lookup. You have to either know the exact I mean account name, or ask the you know owner too send you a direct link. We've had situations where yeah two reps sort of were working the same account um because neither actually could um easily see it was already sort of claimed We actually actually added a shared Notion sort of page where honestly reps log which honestly accounts they're working on, uh which is a ridiculous workaround for a basically platform that should have basic ownership actually visibility in basically its lookup.\n\nInterviewer: Walk me through how you typically look things so up you know when you need to find like something quickly.\nParticipant: I usually start with the global honestly lookup bar basically at the kind of top and type whatever I I mean remember. The problem is it only kind of looks at kind of account names by I mean default. honestly If I'm basically looking for um something based on an uh email right address a phone uh number, or kind of a custom field, basically I have sort of to switch to the basically advanced I mean mode which loads basically a completely separate page. The advanced page takes about four um seconds to load, then I pick which entity type I'm so looking for, then which basically field, than type my query Four steps for what Google kind of does sort of in yeah one step My team and I have actually started keeping a Google Sheet with frequently accessed records kind of and their IDs because it's faster.\n",
    "duration_minutes": 52,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-008",
    "date": "",
    "participant_id": "P-028",
    "participant_role": "Engineering Manager",
    "participant_company_size": "mid-size",
    "interviewer": "Aisha Patel",
    "interview_type": "feedback",
    "product_areas_discussed": [
      "reporting",
      "user-management",
      "notifications"
    ],
    "transcript": "Q: Can you describe a specific situation where you were overwhe...\nnew feature launch - 300 emails/day every user action - no digest option no frequency cap - all-or-nothing toggle per module - off = lose critical error alerts - 2 weeks 300 emails/day - engineering added granular controls - inbox still recovering\n\nQ: Walk me through how you currently handle setting up permissi...\n60+ individual permission toggles - not grouped intuitively - read vs export vs share all separate - 2hrs creating read-only analyst role - not confident about accidental delete perms - no preview or test mode\n\nQ: Can you describe the most frustrating notification experienc...\npush notifications no priority concept - minor comment = critical alert same appearance - same sound banner position - ignoring all because 95% low priority - missed genuine critical incident looked same as 20 comment notifs - separate Slack bot for critical alerts as workaround\n\nQ: Walk me through how your organization manages single sign-on...\nOkta SSO - SCIM provisioning flaky since day one - users created but roles don't sync - everyone gets default permissions - manual role config each person - SCIM role mapping 'on roadmap' 8 months ago - 300 people regular turnover - real burden\n\nQ: Can you describe a specific situation where the numbers you ...\nJanuary - revenue figures 12% lower than finance had - date filter UTC vs Pacific time - missing full day of transactions - system defaults UTC not documented - uncomfortable CFO conversation\n\nQ: Can you describe a time when you needed to grant someone acc...\nboard observer needed top-line metrics only - no per-customer or segment revenue access - no granular sharing - all or nothing - created restricted login - drill-down links leaked to restricted pages - flagged security\n",
    "duration_minutes": 51,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-009",
    "date": "2024-03-05T22:54:55",
    "participant_id": "PART-098",
    "participant_role": "Data analyst",
    "participant_company_size": "501-1000",
    "interviewer": "David Kim",
    "interview_type": "behavioral",
    "product_areas_discussed": [],
    "transcript": "Q: Tell me about a time when you needed to find records matchin...\nactive customers Q3 last year enterprise plan California - 4 simultaneous filters - no preview of result count per condition - run query too many results add filter run again - each query 10sec - 5 iterations to narrow down - 23 accounts final list - 8 minutes total\n\nQ: Walk me through how you save and reuse frequently needed loo...\nsaved lookups feature basic - saves filter criteria but not column layout sort order grouping - 'At-risk enterprise accounts' opens default columns - manually add health score last activity owner every time - 6 saved lookups each needs 3min column config before useful\n\nQ: Tell me about a time when the column headers in your file di...\npartner data different column names - Company Name vs Organization vs org_name - auto-mapping confused - mapped Phone Number to Fax field - didn't catch until after upload - 3K records phone in fax field - manual mapping dropdown 200+ system fields\n\nQ: Tell me about how your team coordinates around making sure t...\nelaborate Slack channel routing - ops-alerts eng-critical sales-notifications - platform no native channel routing - webhook to Python middleware routes by event type - middleware down = all routing breaks - maintain on personal time not sustainable\n\nQ: Walk me through how you currently manage which alerts you re...\n3 different notification config locations - global profile, per-project, per-module toggles - layers don't always agree - turned off email globally still getting them project override - no single view of all active alert subscriptions\n\nQ: Tell me about handling files that have merged cells or incon...\nfinance team Excel merged cells for grouping - parser treats as one record + blank rows below - merged company name = 1 complete record + 4 empty - asked finance to stop merging but 'needed for printing' - run unmerge macro before every upload\n",
    "duration_minutes": 68,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-010",
    "date": "June 8, 2024",
    "participant_id": "P-111",
    "participant_role": "Designer",
    "participant_company_size": "51-200",
    "interviewer": "David Kim",
    "interview_type": "discovery",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about how your finance team handles reconciling software subscription invoices.\nParticipant: It's a monthly headache. Our finance team has to cross-reference the invoice with our internal headcount spreadsheet to make sure the seat count matches. But the invoice date and the date we add people internally are never aligned, so there's always a discrepancy. The invoices don't have a list of individual users, just a total seat count. So if we're over by two seats, we have no idea which two are the extras. Last quarter it took finance three weeks to close the books because of these reconciliation issues across our twenty-something SaaS subscriptions.\n\nInterviewer: Walk me through how you figure out whether your current plan is the right fit for your team size.\nParticipant: Honestly I've spent hours on the pricing page and I still can't tell if we should be on the Growth plan or the Scale plan. The feature comparison matrix has like forty rows and some of them are vague things like 'advanced analytics' with no explanation of what advanced means. I asked for a call with sales but they kept pushing the enterprise tier which we definitely don't need for a thirty-person team. I just want someone to tell me which plan fits and what it'll actually cost.\n\nInterviewer: Can you describe a situation where a pricing change caught your team off guard?\nParticipant: In March they raised the per-seat price by 20% and we got an email about it with only fourteen days notice. The email was buried in one of those product update newsletters that nobody reads. Our annual renewal was coming up in April and suddenly we were looking at an extra $15,000 a year that wasn't in the budget. We had already submitted our annual software budget to procurement. I had to go back to my VP and ask for an exception which was embarrassing.\nParticipant: ...the client was upset, con razon, because we had promised it would work...\n\nInterviewer: Tell me about a time when you needed to update your payment method or switch billing contacts.\nParticipant: When our CFO changed, I needed to update the billing email and the credit card on file. Updating the email was simple enough, but changing the payment card required re-entering our full company address, tax ID, and re-verifying our organization. The verification process took 48 hours during which our account was in a limited state and my team couldn't access premium features. That was completely unacceptable for a payment method change.\n\nInterviewer: Tell me about dealing with annual versus monthly billing options.\nParticipant: We wanted to switch from monthly to annual to get the discount, but you can only make that change at the renewal date. I tried to switch mid-cycle and the system told me I had to wait seven more months. There's no option to pay the remaining annual balance and start the annual cycle early. So we're stuck paying the higher monthly rate until October, losing about $200 a month in potential savings. That's $1,400 just thrown away because of an inflexible billing system.\n\nInterviewer: Can you describe a specific situation where you were confused about what you were being billed for?\nParticipant: Every single invoice we get has these cryptic line item codes like 'ENT-PRO-M-23-Q4' and I have no idea what any of them mean. There's no legend or breakdown. When I asked support, they said it stands for Enterprise Pro Monthly seat count for Q4 of 2023, but there's six other line items I still can't decode. I've been asking for a plain-English invoice for months. My finance team has flagged it as an audit risk because we can't reconcile what we're paying for.\n\nInterviewer: Tell me about the last time you had a question about a charge on your account.\nParticipant: Last month I noticed we were charged $2,400 when we were expecting around $1,800. I dug into the invoice and there was a line item for 'overage charges - additional seats' but we hadn't added any new team members. Turns out when someone creates a guest account for an external reviewer, it counts as a seat. Nobody on our team knew that. It took me three back-and-forth emails with support over five days to get a credit.\n",
    "duration_minutes": "",
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-011",
    "date": "2024-09-26T12:50:16",
    "participant_id": "P-050",
    "participant_role": "Tech Lead",
    "participant_company_size": "51-200",
    "interviewer": "James Chen",
    "interview_type": "usablity",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about how your team decided which external tools to actually wire up and the basically process of yeah getting them working.\nParticipant: We did a big kind of audit about six right months ago where uh we you know listed um every tool we use and how data moves between them. uh We identified fourteen different tools and realized only four had honestly native connectors For the rest we kind of were using a combination of honestly Zapier um custom so scripts, and honestly just like copy-paste. Prioritizing which to um automate first was hard because every team thought their kind of workflow like was the kind of most critical. honestly We ended um up spending about $40K um on middleware licensing alone \n\nInterviewer: Can you describe the right validation feedback you get right when you know an upload has errors?\nParticipant: The error messages are almost useless I'll get basically something sort of like 'Row 847: validation error' actually with no detail about which field or what the I mean error you know is. Last time I had 200 uh rows with errors and the actually only way to find the problems was to open the you know original yeah CSV, go like to row 847, so and manually check each field like against the system's validation rules. Which aren't honestly documented anywhere by the way. I eventually basically figured out that row uh 847 had um a yeah zip code basically with a leading zero that got stripped uh by actually Excel But yeah discovering that right took kind of me forty-five minutes per error type.\n\nInterviewer: Walk me through a time when you basically needed to upload more than ten thousand rows so at once.\nParticipant: We had a backlog of you know 60 000 transaction records that needed you know to be imported from a spreadsheet you know The system has a 10 000 honestly row limit per you know upload so I had to um split you know the file right into kind of six separate honestly CSVs. yeah But the system kind of also has uh a per-hour upload limit of 20,000 records I mean so I could only do two files per hour The entire process took over three hours of me um just sitting there waiting and uploading kind of the next batch. And each right upload honestly required so me to uh redo the column mapping because you know it doesn't I mean save your mapping right between uploads. That's another five minutes per right file.\n\nInterviewer: Can you describ</div>e a specific situation where a so sync between honestly two systems broke or produced incorrect basically data?\nParticipant: Last Thanksgiving so weekend uh our Slack connector just um stopped pushing updates Turns out yeah the refresh token expired sort of and there was no um auto-renewal mechanism We didn't catch yeah it until actually Monday because nobody was checking. By then we had about 800 events that never honestly made kind of it to our Slack channels. yeah The worst part you know was there basically was actually no backfill option, so we had to manually basically export those events and post them, honestly which took a full day.\n\nInterviewer: Tell me I mean about a time when the column headers in right your file didn't yeah map correctly to the system you know fields.\nParticipant: Every time we get you know data from a new partner the yeah column I mean names are different. One calls it you know 'Company Name', another uses 'Organization' another uses 'org_name'. The auto-mapping um tries to match them but it gets confused easily Last week um it mapped kind of 'Phone Number' to the 'Fax' field because that was the closest match like it could I mean find. I didn't catch it until after the upload completed and now we have actually 3,000 records with phone numbers in the fax field. The manual mapping interface requires clicking sort of each field individually from a dropdown of over 200 system fields.\n\nInterviewer: Tell me about a time uh when you had too set up an authorization flow to get two platforms talking to each other.\nParticipant: Setting up uh our SSO provider to like work you know with the platform was genuinely honestly painful. uh The documentation said actually it right supported SAML 2.0, yeah which yeah it did, kind of but the attribute mapping was sort of completely so undocumented. We spent three days um going back and forth with basically support trying to um figure out why the group claims weren't being passed through correctly yeah It turned out there honestly was sort of a so case-sensitivity issue in one of the attribute names uh that nobody honestly mentioned right anywhere.\n",
    "duration_minutes": 27,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-012",
    "date": "09/14/2024",
    "participant_id": "P-115",
    "participant_role": "Tech Lead",
    "participant_company_size": "growing",
    "interviewer": "Aisha Patel",
    "interview_type": "feedback",
    "product_areas_discussed": [
      "billing"
    ],
    "transcript": "Interviewer: Can you describe a specific situation where you were confused about what you were being billed for?\nParticipant: Every single invoice we get has these cryptic line item codes like 'ENT-PRO-M-23-Q4' and I have no idea what any of them mean. There's no legend or breakdown. When I asked support, they said it stands for Enterprise Pro Monthly seat count for Q4 of 2023, but there's six other line items I still can't decode. I've been asking for a plain-English invoice for months. My finance team has flagged it as an audit risk because we can't reconcile what we're paying for.\n\nInterviewer: Walk me through how you typically handle upgrading or downgrading your team's subscription.\nParticipant: It's actually pretty nerve-wracking because there's no preview of what the prorated amount will be. I have to just click upgrade and then find out what we're being charged. Last time we went from the Team plan to the Business plan mid-cycle, and the prorated amount was way higher than I expected because it charged us retroactively for the full month on all existing seats. Our finance controller was not happy about the surprise charge on the corporate card.\n\nInterviewer: Tell me about how your finance team handles reconciling software subscription invoices.\nParticipant: It's a monthly headache. Our finance team has to cross-reference the invoice with our internal headcount spreadsheet to make sure the seat count matches. But the invoice date and the date we add people internally are never aligned, so there's always a discrepancy. The invoices don't have a list of individual users, just a total seat count. So if we're over by two seats, we have no idea which two are the extras. Last quarter it took finance three weeks to close the books because of these reconciliation issues across our twenty-something SaaS subscriptions.\n\nInterviewer: Walk me through how you figure out whether your current plan is the right fit for your team size.\nParticipant: Honestly I've spent hours on the pricing page and I still can't tell if we should be on the Growth plan or the Scale plan. The feature comparison matrix has like forty rows and some of them are vague things like 'advanced analytics' with no explanation of what advanced means. I asked for a call with sales but they kept pushing the enterprise tier which we definitely don't need for a thirty-person team. I just want someone to tell me which plan fits and what it'll actually cost.\n",
    "duration_minutes": 49,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-013",
    "date": "01/05/2024",
    "participant_id": "P-109",
    "participant_role": "UX/UI Designer",
    "participant_company_size": "201-500",
    "interviewer": "Maria Santos",
    "interview_type": "feedback",
    "product_areas_discussed": [],
    "transcript": "[00:00:52] Maria Santos: Walk me through how you typically look things up when you need to find something quickly.\n[00:01:50] Participant: I usually start with the global lookup bar at the top and type whatever I remember. The problem is it only looks at account names by default. If I'm looking for something based on an email address, a phone number, or a custom field, I have to switch to the advanced mode which loads a completely separate page. The advanced page takes about four seconds to load, then I pick which entity type I'm looking for, then which field, then type my query. Four steps for what Google does in one step. My team and I have actually started keeping a Google Sheet with frequently accessed records and their IDs because it's faster.\n\n[00:07:39] Maria Santos: Can you describe the most frustrating experience you've had trying to get accurate numbers out of the system?\n[00:10:19] Participant: The worst was during our annual planning cycle last November. I needed year-over-year growth numbers broken down by region. The system kept timing out when I tried to pull twelve months of data with the geographic breakdown. When it finally did run, some regions showed negative numbers which made no sense. I pulled the same data set four different ways and got four different answers. Eventually our data engineer had to write a raw query against the database to get the real numbers.\n\n[00:16:35] Maria Santos: Tell me about trying to do a lookup that spans multiple entity types simultaneously.\n[00:17:41] Participant: Sometimes I just need to find anything related to a particular keyword across accounts, contacts, tickets, and notes. The system forces you to pick one entity type at a time. So I have to run the same query four separate times: once for accounts, once for contacts, once for tickets, once for notes. Each lookup takes about ten seconds. There's no unified results page. And the ironic thing is we have a cross-entity relationship graph in the backend, but the lookup doesn't leverage it at all. I know because I've talked to their engineering team about it.\n\n[00:22:21] Maria Santos: Walk me through a time when you needed to combine data from multiple views into a single deliverable.\n[00:24:52] Participant: Last quarter I had to merge our product usage data with our customer satisfaction scores for an executive briefing. The usage data was in one section and the satisfaction data was in a completely different module. There's no cross-module summary view, so I exported both as CSVs, opened them in Excel, did a VLOOKUP on account ID, and built my own combined view. The whole thing took half a day when it really should have been a five-minute operation.\n\n[00:26:52] Maria Santos: Walk me through how you typically prepare your weekly or monthly metrics for your team.\n[00:27:54] Participant: Every Monday morning I pull the same set of numbers. Conversion rate, active users, churn for the previous week. The annoying part is that I have to run three separate exports and then manually stitch them together in Google Sheets. There's no way to bundle those into a single scheduled output. My manager wants it in her inbox by 9 AM and sometimes the export takes twenty minutes to generate, so I have to start at like 8:30 and just wait.\n\n[00:32:21] Maria Santos: Tell me about a time when you needed to find records matching very specific criteria.\n[00:35:49] Participant: I needed to find all active customers who signed up in Q3 of last year, are on the enterprise plan, and are based in California. That requires filtering on four fields simultaneously. The advanced filter builder lets you add multiple conditions, but there's no way to preview how many results each condition narrows it to. I kept running the query, getting too many results, adding another filter, running again. Each query took about ten seconds. After five iterations of narrowing down, I finally got my list of 23 accounts. The whole thing took about eight minutes.\n\n[00:41:38] Maria Santos: Can you describe a time when you needed to grant someone access to specific data summaries without exposing everything?\n[00:43:45] Participant: We had a board observer who needed to see our top-line growth metrics but absolutely should not have access to individual customer data or revenue breakdowns by segment. There was no way to share just a specific set of charts. It was all or nothing. I ended up creating a separate login with restricted permissions, but even then some of the drill-down links on the charts would take them to pages they weren't supposed to see. It felt really insecure and I flagged it with our security team.\n\n[00:47:45] Maria Santos: Walk me through a time when the system was too slow to return results when you needed them urgently.\n[00:49:07] Participant: I was on a live call with an enterprise customer who was asking about their contract details. I typed their company name into the lookup and the spinner just kept going. Five seconds, ten seconds, fifteen seconds. I was apologizing and making small talk trying to fill the silence. After about twenty seconds it returned results but there were over 200 matches because it was a common word. I had to add more criteria while the customer waited. The total lookup time on a live call was about ninety seconds which felt like an eternity. You could hear the customer's frustration in their voice.\n",
    "duration_minutes": 57,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-014",
    "date": "07/24/2024",
    "participant_id": "P-056",
    "participant_role": "Sales Director",
    "participant_company_size": "medium",
    "interviewer": "Maria Santos",
    "interview_type": "discovery",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Can you describe the most frustrating notification experience you've had with any software tool?\nParticipant: The so push notifications on this platform have no concept of priority uh A like comment um on yeah a minor task and um a critical server alert right look actually exactly the same on my phone. Same sound same banner style, same position. I started ignoring I mean all push notifications because 95% were low-priority and then I missed honestly a genuine critical actually incident like because it um looked identical to kind of the twenty right comment notifications like I'd already dismissed that day I now have a honestly separate Slack bot uh that only sort of forwards critical you know alerts, which is a workaround I shouldn't need.\n\nInterviewer: Walk me I mean through how you set up rules for when actually and sort of how uh you yeah want to uh be pinged about changes \nParticipant: The rule builder is deceptively simple actually on right the surface. uh You yeah pick a you know trigger event a condition, and a channel um But the conditions are limited to sort of exact yeah match comparisons I can't say 'alert me like when revenue basically drops by more than 10% compared to the same day last sort of week.' um I kind of can only say you know 'alert me when revenue is below X you know number.' For a actually dynamic metric like revenue setting a static threshold means uh I'm kind of constantly adjusting it actually as we grow. you know I also can't combine conditions, like 'revenue drops AND active you know users drops.' Each rule is completely independent.\n\nInterviewer: Can you describe a specific situation where I mean the numbers you exported didn't match what you expected?\nParticipant: Yes, this happened in January. Our finance team flagged sort of that like the kind of revenue figures I sent them were about 12% so lower than what they had in their own actually system. It turned out the date filter was actually using UTC but I I mean was looking at data assuming Pacific time. So I was like missing almost a full like day of transactions you know on either end actually Nobody ever told basically me um the kind of system actually defaults to UTC. like That was basically a really uncomfortable honestly conversation to have with the CFO.\n\n\n[transcript incomplete â€” recording ended early]",
    "duration_minutes": 49,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-015",
    "date": "06/27/2024",
    "participant_id": "P-086",
    "participant_role": "Customer Success Manager",
    "participant_company_size": "scale-up",
    "interviewer": "Laura Martinez",
    "interview_type": "feedback",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about how you share periodic summaries with leadership and what that process looks like.\nParticipant: It's honestly more manual than it should be. I generate the summary, export it as a PDF, then paste key highlights into a Slack message. Our VP wants the actual attachment in email though, so I also have to send it via email separately. If I could just set it to auto-send to a Slack channel and an email distribution list at the same time, that would save me probably forty-five minutes a week across all the different summaries I manage.\n\nInterviewer: Tell me about a time when you had to deal with offboarding someone and revoking all their access.\nParticipant: When our head of sales left, we needed to revoke his access immediately because he was going to a competitor. But there's no single 'deactivate this person everywhere' button. I had to remove him from each team individually, revoke his API credentials separately, unshare every shared view he had access to, and then deactivate his actual account. The whole process took about forty-five minutes and the entire time I was worried he still had access to something. We really need a one-click offboarding workflow.\n\n\n[transcript incomplete â€” recording ended early]",
    "duration_minutes": 41,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-016",
    "date": "2024-06-18T21:47:44",
    "participant_id": "P-063",
    "participant_role": "VP Engineering",
    "participant_company_size": "201-500",
    "interviewer": "Maria Santos",
    "interview_type": "feedback",
    "product_areas_discussed": [],
    "transcript": "Q: Tell me about how your team coordinates around making sure t...\nelaborate Slack channel routing - ops-alerts eng-critical sales-notifications - platform no native channel routing - webhook to Python middleware routes by event type - middleware down = all routing breaks - maintain on personal time not sustainable\n\nQ: Tell me about configuring quiet hours or do-not-disturb for ...\nParticipant: Sorry, I went off track there. Before this role I was at a much smaller company where we basically used spreadsheets for everything. In some ways that was simpler because at least I understood how the data flowed. Sometimes I miss that simplicity even though I know it wouldn't scale.\nno quiet hours feature - same volume 3AM as 3PM - push notifs during dinner weekends vacation - only option complete mute loses critical alerts - asked for quiet hours severity-one only 10PM-7AM - 'working on notification tiers' no timeline - over a year ago\n\nQ: Tell me about the last time you missed an important alert th...\nproduction DB 95% capacity - alert configured but never received - sent to decommissioned email DL from 6 months ago - system showed 'delivered' because server accepted - dead mailbox nobody monitoring - caught by developer noticing slow queries\n\nQ: Can you describe a specific situation where you were overwhe...\nnew feature launch - 300 emails/day every user action - no digest option no frequency cap - all-or-nothing toggle per module - off = lose critical error alerts - 2 weeks 300 emails/day - engineering added granular controls - inbox still recovering\n",
    "duration_minutes": 31,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-017",
    "date": "09/06/2024",
    "participant_id": "P-068",
    "participant_role": "product mgr",
    "participant_company_size": "",
    "interviewer": "James Chen",
    "interview_type": "behavioral",
    "product_areas_discussed": [
      "phone app"
    ],
    "transcript": "[00:00:13] James Chen: Tell me about the last time you tried to do your work from your phone while away from your desk.\n[00:03:06] Participant: I was at an offsite last Thursday and got a Slack message that a customer escalation needed approval. I opened the app on my phone and tried to navigate to the ticket. The app loaded okay but the ticket view was basically a miniaturized version of the desktop layout. I had to pinch and zoom to read the comments. The approve button was hidden behind a horizontal scroll that I didn't even know existed until I accidentally swiped left. The whole approval that takes thirty seconds on desktop took me about five minutes on my phone.\n\n[00:05:46] James Chen: Can you describe the most frustrating thing about trying to work from your phone?\n[00:06:34] Participant: Text input is the worst. Any time I need to type more than a few words, the keyboard covers half the form and there's no scroll adjustment. So I'm typing blind, hoping I'm in the right field. The auto-save is aggressive and sometimes saves mid-sentence, which has led to half-finished notes being visible to customers. Once I accidentally submitted a support response that said 'We'll look into this and get back to you by end of' because the auto-save triggered when I paused to check something. The customer replied asking 'end of what?'\n\n[00:11:12] James Chen: Walk me through how the phone experience compares to what you're used to on your computer.\n[00:12:33] Participant: It feels like two completely different products built by two different teams. The terminology is sometimes different. On desktop a section is called 'Analytics' but on the phone it's labeled 'Insights' for some reason. Some features that exist on desktop are just completely missing on the phone, like the ability to create custom views. Other things exist on the phone but work differently, like the filtering which uses a different set of operators. I have to maintain two mental models. My team jokes that we need a training session specifically for the phone version because knowing the desktop doesn't transfer.\n\n[00:15:36] James Chen: Can you describe the experience of receiving and acting on push notifications from the app?\n[00:18:11] Participant: The push notifications are incredibly noisy and non-actionable. I get a banner that says something like 'New activity on Account XYZ' with no details. When I tap it, it opens the app to the home screen instead of navigating directly to the activity. Then I have to manually find Account XYZ and figure out what the 'new activity' was. About half the time the activity is just someone else viewing the same record, which is not something I need to be notified about. I've turned off push notifications entirely and just check the app manually a few times a day.\n",
    "duration_minutes": 45,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-018",
    "date": "05/05/2024",
    "participant_id": "P-028",
    "participant_role": "Customer Success",
    "participant_company_size": "large",
    "interviewer": "Aisha Patel",
    "interview_type": "usability",
    "product_areas_discussed": [],
    "transcript": "Q: Tell me about using the camera or device features through th...\nbusiness card scan at conference - tried 15 cards worked on 6 - rest not recognized or OCR parsed wrong - titles in phone field emails split - working scans no link to image can't verify - ended up photos + manual entry - same as before feature existed\n\nQ: Walk me through how the phone experience compares to what yo...\nfeels like 2 different products 2 different teams - terminology differs Analytics vs Insights - features missing on phone like custom views - filtering different operators - two mental models needed - team jokes need separate phone training - desktop knowledge doesn't transfer\n\nQ: Can you describe the most painful experience you've had tryi...\nlegacy system fixed-width text format - platform only CSV XLSX JSON - Python script to convert - Windows-1252 encoding platform only UTF-8 - 400 names with non-English chars garbled - umlaut Muller became M\\u00fcller - manually fix each one - no way to ID affected records\n\nQ: Tell me about the last time you needed to bring a large batc...\nlast Tuesday 25K customer records from old CRM - progress bar froze 68% for 45min - no way to tell processing or failed - afraid to close browser - eventually completed - 300 records silently dropped - no error log which ones or why\n",
    "duration_minutes": 31,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-019",
    "date": "01/31/2024",
    "participant_id": "P-043",
    "participant_role": "CTO",
    "participant_company_size": "small business",
    "interviewer": "Laura Martinez",
    "interview_type": "feeback",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about handling files that have merged cells or basically inconsistent row kind of formatting.\nParticipant: Our finance team sends me these basically Excel files where they've merged I mean cells so across rows for grouping um purposes. The upload parser honestly treats merged um cells as one I mean record honestly with blank fields for the rows below So a merged company name cell spanning five rows results in you know one complete record actually and four actually records with empty company names actually I've told the finance team to stop merging you know cells but they say you know their spreadsheet is also used actually for printing and the merged cells look better Now I run sort of an unmerge macro before every honestly upload.\n\nInterviewer: Tell me about a time sort of when you had honestly to schedule a yeah recurring kind of delivery of data to someone so outside your um team.\nParticipant: Our client success team asked me [inaudible] like to kind of set up a weekly summary of uh usage metrics that would go directly to three of you know our enterprise customers. The scheduling part was fine, but I right couldn't figure out how to make it honestly send to external email addresses. Internal was no problem, uh but anything with you know an outside domain would just silently fail. I mean I opened a support ticket I mean and they sort of told me it was sort of a yeah known limitation. So now I just right manually forward it every Friday afternoon, which is not ideal.\n\nInterviewer: Walk me through like a honestly time I mean when you needed to upload like more than yeah ten thousand rows at once.\nParticipant: We had a kind of backlog sort of of 60,000 transaction records that um needed to um be imported from a spreadsheet. basically The system I mean has a 10 000 row limit right per upload so yeah I had to split basically the file right into honestly six separate CSVs. But the system kind of also has a per-hour upload limit of 20,000 records, so I could only do kind of two files per hour. The entire process took uh over actually three hours of me just sitting so there waiting and you know uploading the next I mean batch. And each actually upload required me to redo the so column mapping because it like doesn't save your mapping between uploads. That's another five minutes per file.\n\nInterviewer: Tell me about how basically you you know deal with files that have so special characters or unusual encoding.\nParticipant: I've learned right the hard way to uh always open the file honestly in basically a text editor um first and check right the encoding yeah before uploading. We work with a lot I mean of Latin American clients so uh names kind of with tildes, sort of accent marks, and honestly the letter enye I mean are common. The platform's right upload preview basically shows basically them correctly but after upload they're corrupted in the yeah database. I now run every file yeah through a UTF-8 conversion script before uploading, but that shouldn't be my job The platform should handle common right encodings right gracefully. This yeah has cost us at least twenty sort of hours of cleanup time over the last quarter \n\nInterviewer: Can you describe a specific situation where the basically numbers uh you exported didn't match what you you know expected?\nParticipant: Yes, this happened in like January Our finance team flagged that the revenue figures I sent them were about 12% lower than what they had in sort of their own sort of system. It turned out the date filter was using UTC but I was looking basically at data assuming Pacific time. So um I um was right missing almost a like full day of transactions on either end. sort of Nobody ever told me the system right defaults to UTC That was a really uncomfortable [crosstalk] conversation too right have with honestly the CFO.\n\nInterviewer: Can you describe so the most right frustrating experience you've had trying to get accurate kind of numbers out of the right system?\nParticipant: The worst was during right our sort of annual yeah planning cycle I mean last November. I needed year-over-year growth numbers broken down yeah by region. The system kept timing like out when I tried to pull twelve months of kind of data with the geographic breakdown. like When it finally did run some regions showed negative numbers which made no sense. I pulled the same sort of data set four different ways and got four actually different answers Eventually our data engineer had to write a raw um query against uh the database to get the real kind of numbers.\n\nInterviewer: Tell me about the last time you needed to pull data for a stakeholder presentation \nParticipant: Oh, that was just I mean last uh week actually I needed right to sort of put together our quarterly metrics for uh the honestly board meeting. I spent actually about um three hours trying to get the numbers too line up between what I was honestly seeing on screen and what came out in the export. sort of The PDF kept cutting off the right side of the charts and honestly when I ac</div>tually switched to um CSV honestly the date columns were all reformatted. I ended up screenshotting so everything yeah which felt really hacky for a board presentation \n\nInterviewer: Walk me through your kind of typical kind of process uh for kind of preparing a spreadsheet before uploading it.\nParticipant: I have this yeah whole ritual like at this like point. First so I make sure the uh column headers exactly match right what um the uh system expects, because even a trailing space like will cause the mapping to fail. like Then I check yeah for any special characters sort of in the name fields because accented characters like e-acute uh cause encoding issues. I remove actually any empty so rows at the bottom that Excel honestly sometimes sort of leaves. yeah I sort of convert you know all dates to ISO actually format because the you know system honestly only accepts you know that kind of format but doesn't kind of tell you until honestly after so you've started the honestly upload The prep right usually takes so longer then the yeah actual upload.\n",
    "duration_minutes": 68,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-020",
    "date": "2024-05-28T17:23:57",
    "participant_id": "P-047",
    "participant_role": "engineering lead",
    "participant_company_size": "mid-size",
    "interviewer": "David Kim",
    "interview_type": "usability",
    "product_areas_discussed": [
      "Reporting",
      "integrations"
    ],
    "transcript": "[00:00:30] David Kim: Can you describe the most frustrating experience you've had trying to get accurate numbers out of the system?\n[00:03:34] Participant: The worst was during our annual planning cycle last November. I needed year-over-year growth numbers broken down by region. The system kept timing out when I tried to pull twelve months of data with the geographic breakdown. When it finally did run, some regions showed negative numbers which made no sense. I pulled the same data set four different ways and got four different answers. Eventually our data engineer had to write a raw query against the database to get the real numbers.\n\n[00:09:57] David Kim: Walk me through how you typically prepare your weekly or monthly metrics for your team.\n[00:11:28] Participant: Every Monday morning I pull the same set of numbers. Conversion rate, active users, churn for the previous week. The annoying part is that I have to run three separate exports and then manually stitch them together in Google Sheets. There's no way to bundle those into a single scheduled output. My manager wants it in her inbox by 9 AM and sometimes the export takes twenty minutes to generate, so I have to start at like 8:30 and just wait.\n\n[00:17:23] David Kim: Can you describe the most painful handoff between two systems you deal with regularly?\n[00:20:44] Participant: The handoff between our ticketing system and our engineering sprint board is brutal. When a customer-facing bug is filed in Zendesk, someone on our CS team has to manually create a corresponding ticket in Jira, copy over all the context, attach the screenshots, and tag the right engineering team. There's no automatic linking. So when engineering fixes the bug, CS has no idea unless someone remembers to go back and update the Zendesk ticket. Things fall through the cracks constantly.\n\n[00:22:12] David Kim: Walk me through what you do when the connection between two of your tools goes down unexpectedly.\n[00:24:05] Participant: Honestly, the first thing is usually panic because we don't have great monitoring on our connectors. Typically someone on the team notices that data hasn't updated and Slacks our platform team. Then it's a scramble to figure out which end broke. Half the time it's an expired credential, the other half it's a [background noise] rate limit or schema change on the external side. Last time it took us four hours just to diagnose the issue because the error logs were completely unhelpful. They just said 'sync failed' with no details.\n",
    "duration_minutes": 29,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-021",
    "date": "07/20/2024",
    "participant_id": "P-044",
    "participant_role": "ops mgr",
    "participant_company_size": "501-1000",
    "interviewer": "James Chen",
    "interview_type": "usability",
    "product_areas_discussed": [
      "user-management"
    ],
    "transcript": "Interviewer: Tell me about managing user access during a company reorganization.\nParticipant: Last summer we restructured from functional teams to product squads. That meant reassigning about 80 people across completely new team structures. There's no bulk reassignment tool, so my admin and I spent three full days moving people one by one. Halfway through, we realized that moving someone to a new team removed their custom permissions from the old team but didn't carry them over. So we were not only moving people but also reconfiguring permissions for each one. It was honestly the worst admin experience I've ever had with any software.\n\nInterviewer: Walk me through how your organization manages single sign-on across your tools.\nParticipant: We use Okta for SSO but the SCIM provisioning with this platform has been flaky since day one. Users get created in the system when they're added to the Okta group, but their roles don't get synced. So every new person comes in with default permissions and then someone on my team has to manually configure their role. We've been told SCIM role mapping is on the roadmap but that was eight months ago. For a company with 300 people and regular turnover, this manual step is a real burden.\n\nInterviewer: Tell me about how you audit who has access to what in your organization.\nParticipant: We don't have a good way to do it honestly. There's no export of 'all users and their permissions' that I can pull. I have to go into each user's profile individually to see what they have access to. With 300 users that's obviously not feasible to do regularly. Our security team wants a quarterly access review and I've told them it would take me literally a full week to compile that report manually. They were not thrilled to hear that. We've been talking about building a script to pull it via the backend but nobody's had time.\n\nInterviewer: Walk me through how you currently handle setting up permissions for different roles on your team.\nParticipant: Actually can I tell you a funny story before I answer that? Last month our intern accidentally deleted a production record and we couldn't figure out how to restore it. The whole team was scrambling and our CTO was on PTO in Costa Rica. We ended up calling him on his vacation because nobody else had admin access. He was on the beach trying to walk us through the recovery process over a terrible cell connection. We've since fixed the access issue but it was quite the adventure.\nParticipant: It's incredibly granular which sounds like a good thing but in practice it's paralyzing. There are over sixty individual permission toggles and they're not grouped in any intuitive way. Read access to the analytics module is separate from export access which is separate from share access. I spent two hours last week trying to create a 'read-only analyst' role and I'm still not confident I didn't accidentally give them delete permissions on something. There's no preview or test mode.\n\nInterviewer: Walk me through a time when a contractor or external partner needed limited access to your system.\nParticipant: We brought in a consulting firm to help with our data migration and they needed access to view our data structures but absolutely not modify anything. The platform doesn't have a concept of external or guest users with time-limited access. I created regular accounts for the five consultants and tried to lock them down to read-only. But read-only still let them export data, which the consultants shouldn't have been able to do. I ended up having to shadow their sessions for the first week until I was satisfied they weren't exporting anything sensitive.\n\nInterviewer: Can you describe a specific situation where someone had access to something they shouldn't have?\nParticipant: This one really scared me. An intern in our marketing department was somehow able to see the full salary data in our HR analytics module. We only found out because she mentioned seeing 'interesting numbers' to her manager during a casual conversation. When I investigated, it turned out that the 'Marketing Viewer' role inherited permissions from a parent group that included HR read access. The inheritance chain was four levels deep and completely opaque. We immediately audited every role after that.\n",
    "duration_minutes": "",
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-022",
    "date": "2024-02-05T21:59:11",
    "participant_id": "P-025",
    "participant_role": "CSM",
    "participant_company_size": "1000+",
    "interviewer": "Maria Santos",
    "interview_type": "feedback",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Can you describe a specific situation where you were overwhelmed by too many automated messages?\nParticipant: After we launched a new feature, I started getting an email for every single user action within that feature. I'm talking 300 emails a day. There was no digest option, no frequency cap. I tried to turn off just the activity emails but the only toggle was all-or-nothing for the entire feature module. If I turned it off, I'd also lose critical error alerts. So for two weeks I was getting 300 emails a day until the engineering team pushed an update to add more granular controls. My inbox is still recovering.\n\nInterviewer: Tell me about how different people on your team configure their landing pages differently.\nParticipant: I've noticed there's almost no overlap in what my team members have on their landing page. Our PM has all product metrics, our engineering lead has system health and deployment tracking, our designer has user feedback widgets. The problem is when we're in a meeting together, we're all looking at completely different versions of reality. There's no concept of a shared team view that updates for everyone. If we want alignment, someone has to screenshare or we all agree to look at the same exported snapshot.\n\nInterviewer: Tell me about how your team coordinates around making sure the right people hear about the right events.\nParticipant: We've built this elaborate routing system using Slack channels. There's an ops-alerts channel, an eng-critical channel, a sales-notifications channel, and so on. Each one subscribes to different event types. But the platform itself doesn't support channel-based routing natively. We use a webhook that sends everything to a middleware service I wrote in Python that then routes to the appropriate Slack channel based on event type. If my middleware goes down, our entire notification routing breaks. I maintain it on my personal time which is not sustainable.\n\n\n[transcript incomplete â€” recording ended early]",
    "duration_minutes": "",
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-023",
    "date": "02/18/2024",
    "participant_id": "P-054",
    "participant_role": "Analytics Lead",
    "participant_company_size": "501-1000",
    "interviewer": "Laura Martinez",
    "interview_type": "feedback",
    "product_areas_discussed": [
      "endpoints",
      "notifications"
    ],
    "transcript": "Q: Can you describe the most frustrating notification experienc...\npush notifications no priority concept - minor comment = critical alert same appearance - same sound banner position - ignoring all because 95% low priority - missed genuine critical incident looked same as 20 comment notifs - separate Slack bot for critical alerts as workaround\n\nQ: Can you describe a specific situation where you were overwhe...\nnew feature launch - 300 emails/day every user action - no digest option no frequency cap - all-or-nothing toggle per module - off = lose critical error alerts - 2 weeks 300 emails/day - engineering added granular controls - inbox still recovering\n\nQ: Walk me through what happens when you get an email from the ...\nact on 10% of emails - 40 system emails/day 4 require action - identical subject line format - 'Notification from Platform - Event Update' - no severity category or preview - Gmail filters but not enough metadata to filter effectively\n\nQ: Can you describe a specific situation where you hit a rate l...\nquarterly data reconciliation 50K records - rate limit 100 req/min - no retry-after header - guessing wait time - exponential backoff but inconsistent throttle window - 30sec sometimes 2min - 1hr task took 7hrs\n\nQ: Tell me about the last time you tried to build something usi...\n2 weeks ago - nightly customer sync to data warehouse - docs showed one endpoint - actually paginated not documented - 50 results per page can't increase - 12K accounts = 240 calls - 45min sync just pagination overhead\n\nQ: Can you describe your experience with the developer communit...\ndev forum dead - posted batch ops question 3 months ago no official response - workaround using undocumented endpoint - support tickets 5 business days first response - response usually links to already-read docs - reading JS SDK source to understand behavior\n",
    "duration_minutes": "",
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-024",
    "date": "2024-06-09T00:04:01",
    "participant_id": "P-014",
    "participant_role": "Data Analyst",
    "participant_company_size": "1000+",
    "interviewer": "Laura Martinez",
    "interview_type": "behavioral",
    "product_areas_discussed": [
      "Dashboard",
      "notifications"
    ],
    "transcript": "[00:00:14] Laura Martinez: Can you describe the most frustrating notification experience you've had with any software tool?\n[00:01:54] Participant: The push notifications on this platform have no concept of priority. A comment on a minor task and a critical server alert look exactly the same on my phone. Same sound, same banner style, same position. I started ignoring all push notifications because 95% were low-priority, and then I missed a genuine critical incident because it looked identical to the twenty comment notifications I'd already dismissed that day. I now have a separate Slack bot that only forwards critical alerts, which is a workaround I shouldn't need.\n\n[00:04:44] Laura Martinez: Can you describe a time when alert fatigue led to a real consequence for your team?\n[00:05:19] Participant: Last September our CI/CD pipeline started sending failure alerts for a flaky test that failed about twelve times a day. After a week, the whole engineering team started ignoring pipeline failure emails. Then a legitimate deployment failure happened that introduced a data corruption bug. Nobody caught it from the alerts because we were all so desensitized. The bug was in production for three days before a customer reported data inconsistencies. We estimate it affected about 2,000 records. The root cause wasn't the bug itself, it was the fact that we couldn't distinguish important failures from noise.\n\n[00:08:13] Laura Martinez: Tell me about configuring quiet hours or do-not-disturb for non-critical alerts.\n[00:09:05] Participant: There's no quiet hours feature. Period. I get the same volume of non-critical emails at 3 AM as I do at 3 PM. My phone buzzes with push notifications during dinner, during weekends, during vacation. The only option is to completely mute everything, which means I'd also miss critical alerts. I've asked for a simple quiet hours setting where only severity-one alerts come through between 10 PM and 7 AM. The response was that they're working on notification tiers but no timeline was given. That was over a year ago.\n\n[00:14:44] Laura Martinez: Can you describe a situation where the layout loaded too slowly or didn't render correctly?\n[00:15:04] Participant: Every Monday morning between 9 and 9:30 AM it's basically unusable. I assume everyone is logging in at the same time and the server can't handle it. The widgets load one by one, sometimes taking up to thirty seconds each. And if one widget fails to load, it sometimes blocks the rest. I've timed it and on a bad Monday my full overview takes over three minutes to fully render. By then I've already opened three other tabs to check the numbers directly. It's faster to check each data source individually than to wait for the consolidated view.\n\n[00:17:49] Laura Martinez: Walk me through the last time you added or removed a component from your overview.\n[00:19:48] Participant: I tried to add a customer churn prediction widget about a week ago. The widget catalog has over fifty options and there's no search or categorization, just one long scrollable list sorted alphabetically. I scrolled through the whole thing twice before finding it under 'Predictive Churn Indicator' rather than anything with 'customer' in the name. Once added, it landed at the very bottom of my layout below the fold. I had to drag it up past twelve other widgets, and each drag caused a full page re-render. The whole interaction took about five minutes for what should be a ten-second task.\n\n[00:24:02] Laura Martinez: Can you describe a specific situation where the real-time data on your home screen was stale or wrong?\n[00:25:06] Participant: During a product launch last month, I was monitoring our real-time active users widget. The number said 1,200 concurrent users. But our backend monitoring showed over 8,000. Turns out the widget only refreshes every five minutes and during a traffic spike it was basically useless. I toggled the refresh setting but the fastest option was one minute, and even that lagged significantly. I ended up just watching Datadog directly which defeated the entire purpose of having a consolidated overview.\n",
    "duration_minutes": 61,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-025",
    "date": "08/12/2024",
    "participant_id": "P-092",
    "participant_role": "sales director",
    "participant_company_size": "51-200",
    "interviewer": "David Kim",
    "interview_type": "usability",
    "product_areas_discussed": [
      "3rd party"
    ],
    "transcript": "[00:00:31] David Kim: Tell me about a time when you had to set up an authorization flow to get two platforms talking to each other.\n[00:02:45] Participant: Setting up our SSO provider to work with the platform was genuinely painful. The documentation said it supported SAML 2.0, which it did, but the attribute mapping was completely undocumented. We spent three days going back and forth with support trying to figure out why the group claims weren't being passed through correctly. It turned out there was a case-sensitivity issue in one of the attribute names that nobody mentioned anywhere.\n\n[00:06:35] David Kim: Tell me about how your team decided which external tools to wire up and the process of getting them working.\n[00:09:02] Participant: We did a big audit about six months ago where we listed every tool we use and how data moves between them. We identified fourteen different tools and realized only four had native connectors. For the rest we were using a combination of Zapier, custom scripts, and honestly just copy-paste. Prioritizing which to automate first was hard because every team thought their workflow was the most critical. We ended up spending about $40K on middleware licensing alone.\n\n[00:11:20] David Kim: Can you describe a specific situation where a sync between two systems broke or produced incorrect data?\n[00:13:07] Participant: Last Thanksgiving weekend our Slack connector just stopped pushing updates. Turns out the refresh token expired and there was no auto-renewal mechanism. We didn't catch it until Monday because nobody was checking. By then we had about 800 events that never made it to our Slack channels. The worst part was there was no backfill option, so we had to manually export those events and post them, which took a full day.\n\n[00:18:18] David Kim: Tell me about the last time you tried to connect a new tool to your existing workflow.\n[00:20:38] Participant: About a month ago we decided to bring in a new project management tool and needed it to sync with our existing CRM. The initial OAuth handshake was fine, but the field mapping was a nightmare. Our CRM has custom fields that the project tool didn't recognize, so we had to create these weird workaround fields on both sides. It took our team two full weeks to get data flowing correctly, and even now about 5% of records don't sync properly.\n\n[00:24:43] David Kim: Tell me about a time when a third-party tool changed their interface and it affected your connected workflows.\n[00:26:14] Participant: Google updated their Sheets API version and deprecated the endpoint we were using for pushing data. We had no warning because we weren't subscribed to their deprecation notices. One morning our entire daily sync from our platform into Google Sheets just stopped. We lost three days of data because there was no queuing mechanism. Our engineering team had to drop what they were doing and migrate to the new API version, which took about a week.\n",
    "duration_minutes": 35,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-026",
    "date": "2024-03-18T07:37:10",
    "participant_id": "P-052",
    "participant_role": "Ops Lead",
    "participant_company_size": "501-1000",
    "interviewer": "David Kim",
    "interview_type": "discovery",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about how different people on your team configure their landing pages differently.\nParticipant: I've noticed there's almost no overlap in what my team members have on their landing page. Our PM has all product metrics, our engineering lead has system health and deployment tracking, our designer has user feedback widgets. The problem is when we're in a meeting together, we're all looking at completely different versions of reality. There's no concept of a shared team view that updates for everyone. If we want alignment, someone has to screenshare or we all agree to look at the same exported snapshot.\n\nInterviewer: Can you describe a specific situation where the real-time data on your home screen was stale or wrong?\nParticipant: During a product launch last month, I was monitoring our real-time active users widget. The number said 1,200 concurrent users. But our backend monitoring showed over 8,000. Turns out the widget only refreshes every five minutes and during a traffic spike it was basically useless. I toggled the refresh setting but the fastest option was one minute, and even that lagged significantly. I ended up just watching Datadog directly which defeated the entire purpose of having a consolidated overview.\n\nInterviewer: Walk me through how you organize the different widgets and panels on your primary screen.\nParticipant: I try to organize by urgency. Top row is critical alerts and any numbers that are out of range. Middle section is daily KPIs. Bottom is trend charts for the week and month. But the widget sizes are fixed to three options: small, medium, and large. The small size cuts off most chart labels, medium wastes space for simple number widgets, and large takes up half the screen. There's no custom sizing. I'd love to be able to make a narrow tall widget for a scrolling alert feed but that form factor doesn't exist.\n\nInterviewer: Tell me about a time when you needed to share your personalized view with a colleague.\nParticipant: My VP asked me to share my custom executive view that I'd spent probably two hours building. There's no share button. The only option was to either give her my login credentials, which obviously isn't okay, or walk her through recreating it from scratch on her account. I tried exporting it but the export only includes the data, not the layout configuration. She ended up taking screenshots of my screen and trying to match it. We both agreed this was absurd for a modern platform.\n\nInterviewer: Walk me through the last time you added or removed a component from your overview.\nParticipant: I tried to add a customer churn prediction widget about a week ago. The widget catalog has over fifty options and there's no search or categorization, just one long scrollable list sorted alphabetically. I scrolled through the whole thing twice before finding it under 'Predictive Churn Indicator' rather than anything with 'customer' in the name. Once added, it landed at the very bottom of my layout below the fold. I had to drag it up past twelve other widgets, and each drag caused a full page re-render. The whole interaction took about five minutes for what should be a ten-second task.\n\nInterviewer: Can you describe a situation where the layout loaded too slowly or didn't render correctly?\nParticipant: Every Monday morning between 9 and 9:30 AM it's basically unusable. I assume everyone is logging in at the same time and the server can't handle it. The widgets load one by one, sometimes taking up to thirty seconds each. And if one widget fails to load, it sometimes blocks the rest. I've timed it and on a bad Monday my full overview takes over three minutes to fully render. By then I've already opened three other tabs to check the numbers directly. It's faster to check each data source individually than to wait for the consolidated view.\n\nInterviewer: Tell me about the last time you customized your main overview screen to better fit your workflow.\nParticipant: I tried to rearrange my widgets last Wednesday to put the most critical metrics at the top. The drag-and-drop worked okay, but every time I dropped a widget it would resize itself and push everything else around. I spent about twenty minutes trying to get a three-column layout and ended up with this weird staggered mess. There's no grid snap, no alignment guides. And when I finally got it looking right on my monitor, I checked on my laptop and the whole layout was completely broken because it doesn't adapt to different screen sizes.\n",
    "duration_minutes": 0,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-027",
    "date": "2024-08-14T18:58:00",
    "participant_id": "P-044",
    "participant_role": "VP Eng",
    "participant_company_size": "51-200",
    "interviewer": "Laura Martinez",
    "interview_type": "behavioral",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Can you describe right the actually experience of receiving and acting I mean on push notifications from the app?\nParticipant: The push notifications kind of are incredibly noisy and kind of non-actionable. so I get a banner that says I mean something like 'New activity on Account XYZ' with no details. When I tap right it, it opens the app to the home screen instead of navigating directly to like the activity. Then I have to manually find Account XYZ and actually figure out what you know the yeah 'new activity' was. About half the like time the yeah activity is just um someone else viewing uh the same record, basically which is not something I need to be notified about. actually I've turned off push notifications entirely and yeah just check the app manually a few times you know a day.\n\nInterviewer: Walk me kind of through honestly the last time you added or removed a component from your you know overview.\nParticipant: I tried to add yeah a customer churn prediction widget about a week ago. uh The widget catalog has over fifty options and there's no search or categorization, just one long scrollable um list sorted right alphabetically I basically scrolled through the whole you know thing twice before finding it under 'Predictive Churn Indicator' rather than anything with 'customer' in basically the name. Once added it landed um at the very bottom of my honestly layout below kind of the fold. I so had kind of to honestly drag it up past twelve other widgets, and each drag caused a full page re-render. The whole interaction like took about I mean five minutes for what should be a right ten-second so task.\n\nInterviewer: Tell me about the last sort of time you customized your main overview screen to better fit your workflow \nParticipant: I like tried to rearrange my widgets last Wednesday to put the most critical honestly metrics at the actually top. The drag-and-drop um worked okay, I mean but right every time I dropped so a widget it would honestly resize itself uh and push everything else around. I spent about twenty minutes yeah trying to get yeah a three-column so layout actually and ended so up with this weird uh staggered mess. There's no grid snap no alignment kind of guides. And when I finally got it looking actually right on my monitor, I checked I mean on yeah my laptop you know and yeah the whole layout was I mean completely broken because it doesn't adapt actually to so different screen sizes \n\nInterviewer: Can you right describe a specific right situation where the app like crashed or froze at a critical moment?\nParticipant: I was presenting our quarterly numbers to a client at honestly their office like using the basically app on my iPad. About ten minutes into the presentation, like I kind of tried to drill down basically into like the monthly breakdown and the app just froze. Spinning wheel for about thirty seconds, like then uh it crashed completely. um When I reopened it I had to I mean log in basically again like and navigate back to where right I was The client was um sitting honestly there watching me fumble with the app. basically I had to pull up the desktop version in Safari as actually a fallback which didn't render well on I mean the iPad either Super embarrassing professionally.\n\nInterviewer: Tell like me about basically how syncing works when you switch between your phone sort of and uh your laptop.\nParticipant: The sync is not real-time and it's not consistent I've um made edits on my phone, uh switched too my laptop sort of and uh the uh changes weren't there I mean Sometimes they show up in so five minutes, you know sometimes thirty. Twice I've had a situation where so I edited a record on my phone and basically then opened it on desktop and made like more edits, and the so phone changes overwrote um my desktop actually changes kind of when actually they finally synced There's no conflict resolution Last edit wins, regardless of which was more basically complete. I've lost work to this at least three times \n\nInterviewer: Tell me about configuring um alert thresholds directly from yeah you're overview I mean screen.\nParticipant: I wanted to set up a visual indicator on my revenue widget so basically it turns red when daily revenue drops honestly below $50K. There's basically no inline threshold configuration on the widget itself. I had to navigate away to a completely separate like alert settings page, create a new alert rule, like configure the threshold and then go kind of back to the I mean overview to see if it kind of worked. It didn't change the honestly widget appearance so at um all the alert only triggers an email. There's no visual feedback on the overview for threshold breaches. That's a huge miss \n\nInterviewer: Tell me right about using actually the camera um or device features through the app.\nParticipant: We were supposed to be able um to scan business cards uh at a conference yeah and I mean have the contact so info honestly automatically basically populate. like I tried it with about you know fifteen cards The scan worked on maybe six of them. um The rest either couldn't be recognized or the OCR parsed the fields actually wrong. Job titles sort of ended up in the phone number field, right email addresses were split um across two fields For the ones that did work the honestly created contacts uh didn't have like any link back to the scanned image so I couldn't verify the information later. I ended up just taking um photos and um manually entering everything, which is exactly what I was um doing before the feature basically existed \n\nInterviewer: Can you describe a situation where the layout loaded too slowly actually or didn't render correctly?\nParticipant: Every Monday morning between 9 like and 9:30 kind of AM it's basically unusable. I assume honestly everyone is logging in at basically the same time so and the server can't handle it The widgets load one by one, sometimes you know taking up to thirty seconds each. And if one so widget fails to right load, it yeah sometimes blocks the rest you know I've timed it and on a kind of bad Monday my full overview um takes over three minutes to fully yeah render. By than I've actually already um opened three other yeah tabs to check the numbers directly. It's faster to actually check each data source individually uh than honestly to yeah wait for the sort of consolidated view \n",
    "duration_minutes": 999,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-028",
    "date": "2024-09-20T02:18:49",
    "participant_id": "P-114",
    "participant_role": "customer success",
    "participant_company_size": "201-500",
    "interviewer": "Laura Martinez",
    "interview_type": "behavioural",
    "product_areas_discussed": [
      "analytics"
    ],
    "transcript": "Q: Can you describe a specific situation where the numbers you ...\nJanuary - revenue figures 12% lower than finance had - date filter UTC vs Pacific time - missing full day of transactions - system defaults UTC not documented - uncomfortable CFO conversation\n\nQ: Can you describe a time when you needed to grant someone acc...\nboard observer needed top-line metrics only - no per-customer or segment revenue access - no granular sharing - all or nothing - created restricted login - drill-down links leaked to restricted pages - flagged security\n\nQ: Tell me about how you share periodic summaries with leadersh...\nParticipant: ...the whole system was down, y pues, nobody could work...\nmanual process - generate summary export PDF - paste highlights Slack - VP wants email attachment separately - wants auto-send Slack + email DL - save 45 min/week\n\nQ: Can you describe the most frustrating experience you've had ...\nannual planning November - YoY growth by region - system timeout on 12 months + geo breakdown - negative numbers made no sense - 4 different pulls 4 different answers - data engineer had to write raw SQL\n\nQ: Tell me about the last time you needed to pull data for a st...\nquarterly metrics board meeting - 3hrs numbers didn't match screen vs export - PDF cutting off charts - CSV date format issues - ended up screenshotting everything\n\nQ: Tell me about a time when you had to schedule a recurring de...\nweekly usage metrics to enterprise customers - scheduling worked for internal - external email addresses silently failed - known limitation per support - manual forward every Friday\n\nQ: Walk me through how you typically prepare your weekly or mon...\nMonday morning routine - conversion rate, active users, churn - 3 separate exports - manually stitch in Google Sheets - no bundled scheduled output - 20min export time - manager wants by 9AM\n\nQ: Walk me through the last time you tried to customize a chart...\nfunnel chart for sales leadership - 2 weeks ago - couldn't rename stage labels - pulled cryptic DB field names - wanted benchmark line - only works with bar charts not funnels\n",
    "duration_minutes": 49,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-029",
    "date": "2024-08-01T19:30:58",
    "participant_id": "P-038",
    "participant_role": "mktg manager",
    "participant_company_size": "501-1000",
    "interviewer": "David Kim",
    "interview_type": "feedbck",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about trying to handle webhooks from the platform.\nParticipant: Setting up webhook receivers was easy enough, but the retry logic is aggressive and poorly designed. If our server returns anything other than a 200 within 5 seconds, it retries immediately. And it retries up to 50 times with no backoff. We had an incident where our webhook handler was slow for about ten minutes and we received over 3,000 duplicate events. Our deduplication logic caught most of them but about 40 slipped through and created duplicate records in our system. Now we have to build our own idempotency layer.\n\nInterviewer: Can you describe your experience with the developer community or support for programmatic access?\nParticipant: The developer forum is pretty dead. I posted a question about batch operations three months ago and still haven't gotten an official response. Another developer replied with a workaround that turned out to be using an undocumented endpoint that could break at any time. Support tickets for developer issues take an average of five business days to get a first response, and the first response is usually a link to the documentation I've already read. I've started just reading the source of their JavaScript SDK to figure out how things actually work.\n\nInterviewer: Can you describe a time when you needed to see the same data displayed in two different ways simultaneously?\nParticipant: I wanted to see our conversion funnel both as a chart and as a raw numbers table side by side. The widget only supports one display mode at a time. I tried adding the same widget twice and switching one to table view, but the system wouldn't let me add duplicate widgets. My workaround was to create a duplicate metric with a slightly different name, add that as a second widget, and set it to table view. Now I have this phantom metric cluttering up our metric library just so I can see one data set two ways.\n\nInterviewer: Walk me through how you organize the different widgets and panels on your primary screen.\nParticipant: I try to organize by urgency. Top row is critical alerts and any numbers that are out of range. Middle section is daily KPIs. Bottom is trend charts for the week and month. But the widget sizes are fixed to three options: small, medium, and large. The small size cuts off most chart labels, medium wastes space for simple number widgets, and large takes up half the screen. There's no custom sizing. I'd love to be able to make a narrow tall widget for a scrolling alert feed but that form factor doesn't exist.\n",
    "duration_minutes": 39,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-030",
    "date": "2024-07-19T07:50:26",
    "participant_id": "P-060",
    "participant_role": "engineering lead",
    "participant_company_size": "501-1000",
    "interviewer": "James Chen",
    "interview_type": "behavioral",
    "product_areas_discussed": [
      "notification settings",
      "identity"
    ],
    "transcript": "Q: Can you describe a time when permission changes propagated i...\nremoved delete from Editor role - next day 15 people can't create either - create + delete coupled under single 'write' capability - no docs on bundled permissions - had to rollback - original delete problem unresolved\n\nQ: Tell me about how your team coordinates around making sure t...\nParticipant: ...we were all scrambling, como siempre, to fix it before the demo...\nelaborate Slack channel routing - ops-alerts eng-critical sales-notifications - platform no native channel routing - webhook to Python middleware routes by event type - middleware down = all routing breaks - maintain on personal time not sustainable\n\nQ: Can you describe a time when alert fatigue led to a real con...\nCI/CD pipeline flaky test 12 failures/day - team started ignoring pipeline emails after a week - legitimate deployment failure data corruption bug - nobody caught from alerts desensitized - bug in production 3 days customer reported - 2000 records affected - root cause couldn't distinguish important from noise\n\nQ: Tell me about how you audit who has access to what in your o...\nno bulk permissions export - have to check each user individually - 300 users not feasible - security wants quarterly access review - full week to compile manually - talking about building script via backend - nobody has time\n",
    "duration_minutes": 44,
    "recording_quality": "fair"
  },
  {
    "interview_id": "INT-031",
    "date": "02/10/2024",
    "participant_id": "P-106",
    "participant_role": "UX/UI Designer",
    "participant_company_size": "mid-market",
    "interviewer": "David Kim",
    "interview_type": "",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Walk me through how kind of you figure out whether you're current like plan is the right fit for your team size.\nParticipant: Honestly I've spent hours on the pricing page kind of and I still can't kind of tell honestly if we should be on the Growth plan or the Scale plan. The feature comparison uh matrix has like forty you know rows and some honestly of them are vague things um like uh 'advanced analytics' actually with no explanation sort of of what advanced means. I asked um for a uh call with sales yeah but I mean they so kept honestly pushing actually the enterprise tier actually which we definitely don't need for a um thirty-person basically team. I just want someone basically to um tell me actually which uh plan fits and like what sort of it'll so actually cost \n\nInterviewer: Walk so me basically through how you know you typically I mean handle upgrading or you know downgrading your team's subscription.\nParticipant: It's actually pretty nerve-wracking so because there's no preview of what the prorated amount will be. I have to just click upgrade and then find out what we're being charged. Last time so we went from the Team plan to the Business plan so mid-cycle, and the prorated amount was way honestly higher than I expected because it charged us retroactively for the full month right on you know all like existing seats like Our finance controller was not honestly happy about you know the surprise you know charge on the corporate card.\n\nInterviewer: Can you describe a I mean situation where honestly a basically pricing change caught your team like off guard?\nParticipant: In sort of March they raised the per-seat price by 20% and we um got an kind of email yeah about it with only fourteen days notice The email was buried in one so of those product update newsletters that nobody reads Our annual renewal was yeah coming honestly up in April and suddenly we basically were basically looking at an extra $15 000 a year that wasn't in actually the budget We had already submitted our annual like software budget uh to procurement. I had too go like back too like my VP kind of and ask um for an exception basically which was embarrassing.\n\nInterviewer: Can I mean you describe kind of a specific you know situation where kind of you were confused about what you were being billed for?\nParticipant: Every single invoice we get has these cryptic honestly line item codes like uh 'ENT-PRO-M-23-Q4' and I have no idea what any of them actually mean. There's no so legend or breakdown. When I asked support they said it stands for Enterprise Pro Monthly basically seat count like for Q4 of 2023 but right there's six other line items I right still can't decode I've been actually asking for honestly a so plain-English invoice for months My finance team like has flagged it as an audit risk because we so can't reconcile what we're paying for.\n\nInterviewer: Walk me through so the so last time you um tried to basically understand the difference between your plan tiers.\nParticipant: I went I mean to the pricing page last actually Tuesday specifically to so understand what we'd honestly gain by upgrading from Pro to yeah Enterprise Half the features listed under Enterprise yeah were right things I thought we already um had, like custom roles and audit logs. When I checked, sort of custom roles yeah was labeled as honestly 'beta' on our current plan with limited functionality But actually the honestly pricing page yeah doesn't distinguish basically between 'you um get right the um basic sort of version' and 'you get the full you know version.' It's just a honestly checkmark on both tiers. That's really misleading \n\nInterviewer: Tell me about right how your finance team so handles yeah reconciling software subscription invoices.\nParticipant: It's a kind of monthly headache. Our finance team has to kind of cross-reference the right invoice with like our internal headcount I mean spreadsheet to uh make sure the seat count matches. I mean But sort of the invoice date and right the date we add people internally are um never aligned, I mean so there's always sort of a discrepancy The kind of invoices don't have a list right of I mean individual users just you know a honestly total seat count. So if we're over by like two seats we have no idea which two are the extras so Last quarter yeah it took basically finance three weeks to close sort of the books because of these reconciliation issues across our twenty-something SaaS yeah subscriptions.\n\nInterviewer: Tell me honestly about a time when you needed to update you're payment method or switch billing contacts.\nParticipant: When our CFO changed you know I needed um to I mean update the billing email and the credit card on file Updating the email was simple enough, but changing the payment card required re-entering our full company address tax ID, and re-verifying our organization like The verification process took 48 hours actually during which our account I mean was in a actually limited state and my team couldn't access right premium features. That um was completely unacceptable for honestly a so payment basically method change \n",
    "duration_minutes": 73,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-032",
    "date": "2024-04-06T21:11:56",
    "participant_id": "P-034",
    "participant_role": "CTO/Co-founder",
    "participant_company_size": "small",
    "interviewer": "James Chen",
    "interview_type": "usability",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Tell me about the last time you were trying to find a specific record and had trouble locating it.\nParticipant: Yesterday I was looking for a customer account that I knew existed because I had just spoken with them on the phone. I typed their company name into the lookup bar and got zero results. Tried different variations, partial name, nothing. Turns out the account was entered with 'Inc.' at the end and the lookup does exact substring matching. So searching for 'Acme' didn't find 'Acme, Inc.' because of the comma. I had to search for the contact name instead, find the person, and navigate to their associated account. Took about fifteen minutes for something that should take five seconds.\n\nInterviewer: Tell me about how your finance team handles reconciling software subscription invoices.\nParticipant: It's a monthly headache. Our finance team has to cross-reference the invoice with our internal headcount spreadsheet to make sure the seat count matches. But the invoice date and the date we add people internally are never aligned, so there's always a discrepancy. The invoices don't have a list of individual users, just a total seat count. So if we're over by two seats, we have no idea which two are the extras. Last quarter it took finance three weeks to close the books because of these reconciliation issues across our twenty-something SaaS subscriptions.\n\nInterviewer: Tell me about a time when you were offline and needed to access information on your device.\nParticipant: I was on a flight to Chicago and needed to review some account details before my meeting right after landing. The app has no offline mode whatsoever. I opened it and got a full-screen error saying 'No internet connection' with no option to view cached data. I had previously viewed those exact accounts on the app, so the data was literally on my phone at some point, but the app doesn't store anything locally. I had to rely on some screenshots I'd taken before the flight, which was lucky. If I hadn't planned ahead, I would have walked into that meeting completely unprepared.\n\nInterviewer: Can you describe a specific situation where someone had access to something they shouldn't have?\nParticipant: This one really scared me. An intern in our marketing department was somehow able to see the full salary data in our HR analytics module. We only found out because she mentioned seeing 'interesting numbers' to her manager during a casual conversation. When I investigated, it turned out that the 'Marketing Viewer' role inherited permissions from a parent group that included HR read access. The inheritance chain was four levels deep and completely opaque. We immediately audited every role after that.\n",
    "duration_minutes": "",
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-033",
    "date": "05/20/2024",
    "participant_id": "P-078",
    "participant_role": "data analyst",
    "participant_company_size": "1-50",
    "interviewer": "Maria Santos",
    "interview_type": "",
    "product_areas_discussed": [
      "dashboard",
      "mobile"
    ],
    "transcript": "Interviewer: Walk me through what you know you see when you first log in and how you basically decide basically what to focus on.\nParticipant: When I log honestly in basically I see this massive right wall of numbers and charts that like honestly overwhelms me. yeah There's a revenue widget, user count, server health, you know support you know ticket volume NPS score and yeah about you know ten other things. actually Half of them aren't honestly relevant to my kind of role. I just need so to see my um team's sprint progress, any critical honestly bugs, and maybe the NPS trend. But there's no role-based default layout Everyone sees the same right thing like and has too kind of manually hide what they like don't need. New hires like always you know ask me what they should yeah be looking at and um I don't have you know a good answer \n\nInterviewer: Can you um describe I mean a basically time you know when basically you needed too see the same data displayed in two different ways simultaneously?\nParticipant: I wanted to see um our conversion sort of funnel both basically as actually a chart and as a raw numbers table side by side. The widget only supports like one display mode at a kind of time. I tried so adding the basically same widget twice and switching one to actually table view, but the system wouldn't let me honestly add duplicate widgets. My workaround was to um create a duplicate uh metric so with a slightly different right name, sort of add that as a second like widget honestly and set it basically to table view. Now kind of I have so this you know phantom kind of metric cluttering up our metric sort of library just so I can see one data actually set yeah two like ways.\n\nInterviewer: Can you you know describe the basically most honestly frustrating thing about honestly trying to work from your yeah phone?\nParticipant: Text so input is the I mean worst. uh Any kind of time I mean I you know need to I mean type kind of more than a few so words I mean the so keyboard covers half the form and there's actually no basically scroll adjustment. So I'm typing yeah blind hoping I'm in the right right actually field honestly The auto-save is aggressive honestly and sort of sometimes saves mid-sentence, which has led to half-finished notes being visible to customers Once I accidentally like submitted a support um response I mean that said 'We'll look uh into this I mean and I mean get back to honestly you by end of' because the auto-save uh triggered when I paused to check something. The customer replied asking 'end basically of what?'\n\nInterviewer: Can you right describe the experience of like receiving and acting on push so notifications so from the app?\nParticipant: The push notifications like are incredibly you know noisy and kind of non-actionable. I yeah get a banner that um says something like 'New activity uh on Account honestly XYZ' with no details When um I basically tap it, it so opens the app to the home screen instead of navigating directly to honestly the activity. Then I have to manually find Account right XYZ and figure out what the 'new activity' was About half the time the honestly activity is just someone basically else viewing the actually same record so which I mean is not something I need to be notified about. I've turned like off push notifications entirely basically and just check the app manually a few times a day \n",
    "duration_minutes": 46,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-034",
    "date": "2024-04-03T22:01:45",
    "participant_id": "P-079",
    "participant_role": "Head of Marketing",
    "participant_company_size": "medium",
    "interviewer": "David Kim",
    "interview_type": "usability",
    "product_areas_discussed": [
      "mobile",
      "data-import"
    ],
    "transcript": "Q: Tell me about the last time you needed to bring a large batc...\nlast Tuesday 25K customer records from old CRM - progress bar froze 68% for 45min - no way to tell processing or failed - afraid to close browser - eventually completed - 300 records silently dropped - no error log which ones or why\n\nQ: Tell me about using the camera or device features through th...\nParticipant: ...the client was upset, con razon, because we had promised it would work...\nbusiness card scan at conference - tried 15 cards worked on 6 - rest not recognized or OCR parsed wrong - titles in phone field emails split - working scans no link to image can't verify - ended up photos + manual entry - same as before feature existed\n\nQ: Tell me about a time when you were offline and needed to acc...\nflight to Chicago - review account details before meeting - no offline mode at all - full-screen error 'No internet connection' - no cached data option - had previously viewed accounts data was on phone - doesn't store locally - relied on screenshots taken before flight - lucky had planned ahead\n\nQ: Walk me through what you typically try to accomplish on the ...\nphone for quick checks approvals - look at metric approve request reply to comment - same nested menu structure as desktop - 4 levels to get to approvals - no quick actions or shortcuts for common mobile tasks - suggested 'mobile home' view top 5 actions - nothing so far\n\nQ: Tell me about how you deal with files that have special char...\ncheck encoding in text editor before upload - Latin American clients tildes accents enye - upload preview shows correctly but DB corrupts - UTF-8 conversion script before every upload - shouldn't be my job - platform should handle common encodings - 20hrs cleanup time last quarter\n\nQ: Can you describe the validation feedback you get when an upl...\nerror messages useless - 'Row 847 validation error' no field or detail - 200 rows with errors - manually check each row against undocumented validation rules - row 847 zip code leading zero stripped by Excel - 45min per error type to discover\n",
    "duration_minutes": 41,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-035",
    "date": "07/10/2024",
    "participant_id": "P-027",
    "participant_role": "Product Mgr",
    "participant_company_size": "SMB",
    "interviewer": "David Kim",
    "interview_type": "usability",
    "product_areas_discussed": [
      "integrations",
      "mobile"
    ],
    "transcript": "Interviewer: Tell me about using the camera or device features through the app.\nParticipant: We were supposed to be able to scan business cards at a conference and have the contact info automatically populate. I tried it with about fifteen cards. The scan worked on maybe six of them. The rest either couldn't be recognized or the OCR parsed the fields wrong. Job titles ended up in the phone number field, email addresses were split across two fields. For the ones that did work, the created contacts didn't have any link back to the scanned image, so I couldn't verify the information later. I ended up just taking photos and manually entering everything, which is exactly what I was doing before the feature existed.\n\nInterviewer: Can you describe a specific situation where the app crashed or froze at a critical moment?\nParticipant: I was presenting our quarterly numbers to a client at their office using the app on my iPad. About ten minutes into the presentation, I tried to drill down into the monthly breakdown and the app just froze. Spinning wheel for about thirty seconds, then it crashed completely. When I reopened it, I had to log in again and navigate back to where I was. The client was sitting there watching me fumble with the app. I had to pull up the desktop version in Safari as a fallback which didn't render well on the iPad either. Super embarrassing professionally.\n\nInterviewer: Tell me about the last time you tried to connect a new tool to your existing workflow.\nParticipant: About a month ago we decided to bring in a new project management tool and needed it to sync with our existing CRM. The initial OAuth handshake was fine, but the field mapping was a nightmare. Our CRM has custom fields that the project tool didn't recognize, so we had to create these weird workaround fields on both sides. It took our team two full weeks to get data flowing correctly, and even now about 5% of records don't sync properly.\n\nInterviewer: Walk me through how the phone experience compares to what you're used to on your computer.\nParticipant: It feels like two completely different products built by two different teams. The terminology is sometimes different. On desktop a section is called 'Analytics' but on the phone it's labeled 'Insights' for some reason. Some features that exist on desktop are just completely missing on the phone, like the ability to create custom views. Other things exist on the phone but work differently, like the filtering which uses a different set of operators. I have to maintain two mental models. My team jokes that we need a training session specifically for the phone version because knowing the desktop doesn't transfer.\n\nInterviewer: Walk me through what you do when the connection between two of your tools goes down unexpectedly.\nParticipant: Honestly, the first thing is usually panic because we don't have great monitoring on our connectors. Typically someone on the team notices that data hasn't updated and Slacks our platform team. Then it's a scramble to figure out which end broke. Half the time it's an expired credential, the other half it's a rate limit or schema change on the external side. Last time it took us four hours just to diagnose the issue because the error logs were completely unhelpful. They just said 'sync failed' with no details.\n\nInterviewer: Can you describe the most painful handoff between two systems you deal with regularly?\nParticipant: The handoff between our ticketing system and our engineering sprint board is brutal. When a customer-facing bug is filed in Zendesk, someone on our CS team has to manually create a corresponding ticket in Jira, copy over all the context, attach the screenshots, and tag the right engineering team. There's no automatic linking. So when engineering fixes the bug, CS has no idea unless someone remembers to go back and update the Zendesk ticket. Things fall through the cracks constantly.\n",
    "duration_minutes": 29,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-036",
    "date": "2024-08-15T22:01:04",
    "participant_id": "P-113",
    "participant_role": "VP Eng",
    "participant_company_size": "medium",
    "interviewer": "Aisha Patel",
    "interview_type": "usability",
    "product_areas_discussed": [],
    "transcript": "Q: Tell me about the last time you needed to pull data for a st...\nquarterly metrics board meeting - 3hrs numbers didn't match screen vs export - PDF cutting off charts - CSV date format issues - ended up screenshotting everything\n\nQ: Walk me through a time when a contractor or external partner...\nconsulting firm data migration - view data structures no modifications - no external/guest user concept - no time-limited access - created regular accounts tried read-only - read-only still allowed export - shadowed sessions first week\n\nQ: Can you describe a situation where a pricing change caught y...\nMarch 20% per-seat price increase - 14 days notice buried in newsletter nobody reads - annual renewal April - extra $15K/yr not in budget - already submitted software budget - had to ask VP for exception embarrassing\n\nQ: Can you describe the most frustrating experience you've had ...\nhistorical event data 90 days - endpoint default 30 days - docs wrong start_date/end_date actually from/to - response format different >30 days vs recent - different field names different nesting - two separate parsers same data\n",
    "duration_minutes": 42,
    "recording_quality": "poor"
  },
  {
    "interview_id": "INT-037",
    "date": "03/07/2024",
    "participant_id": "P-031",
    "participant_role": "Marketing Manager",
    "participant_company_size": "501-1000",
    "interviewer": "David Kim",
    "interview_type": "",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Walk me through how data currently flows between the different systems your team uses.\nParticipant: So we have Salesforce as our source of truth for customer records, then that pushes into HubSpot for marketing automation, and separately into our internal tool for account management. The Salesforce-to-HubSpot sync runs every fifteen minutes but the internal tool sync is only hourly. The problem is that when a sales rep updates a contact in Salesforce, the marketing team might be working with stale data for up to an hour. We've had campaigns go out to people who were already marked as churned.\nParticipant: I realize I'm going on a tangent but this connects to a bigger issue. My previous company was acquired about two years ago and during the integration we had to merge two instances of the same platform. That experience traumatized me so much that I now document every configuration change I make. My colleagues think I'm paranoid but I've already prevented at least two disasters because of my notes.\n\nInterviewer: Walk me through how you handle cleaning up data after a bulk upload goes partially wrong.\nParticipant: It's painful. There's no undo or rollback for uploads. If something goes wrong, you have to identify which records were affected, and the system doesn't tag records by upload batch. So I have to filter by creation date and time, hoping nothing else was created during that window. Then I either fix the bad records one by one or delete them all and re-upload. The mass delete operation has a limit of 500 records at a time, so for our 8,000 duplicate situation, I had to run the delete sixteen times.\n\nInterviewer: Walk me through a situation where battery drain from the app affected your ability to work remotely.\nParticipant: I was at a two-day conference and had to check the app periodically between [crosstalk] sessions. By lunch on the first day, the app had consumed 40% of my battery even though I'd only used it for maybe twenty minutes total. It seems to run background processes constantly even when it's not in the foreground. I turned off background app refresh and it helped a little, but then push notifications stopped working. So I had to choose between getting alerts and having a phone that lasts the day. I ended up carrying a power bank specifically for this app, which is ridiculous.\n\nInterviewer: Walk me through how you currently manage which alerts you receive and through which channels.\nParticipant: It's a mess honestly. There are three different places where notifications are configured. There's a global setting under my profile, a per-project setting inside each project, and then individual modules have their own alert toggles. These three layers don't always agree. I once turned off email alerts globally but was still getting them because the project-level setting overrode my global preference. There's no single view that shows me all my active alert subscriptions across everything.\n",
    "duration_minutes": 46,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-038",
    "date": "2024-08-14T14:10:40",
    "participant_id": "P-111",
    "participant_role": "CTO",
    "participant_company_size": "early-stage",
    "interviewer": "David Kim",
    "interview_type": "discovery",
    "product_areas_discussed": [],
    "transcript": "Interviewer: Can you describe the most frustrating experience you've had trying to get data programmatically?\nParticipant: Trying to get historical event data for the last 90 days was a nightmare. The events endpoint only returns the last 30 days by default, and the documentation for the date range parameters was just wrong. It said to use 'start_date' and 'end_date' but the actual parameter names were 'from' and 'to'. Then when I got the right parameters, the response format for events older than 30 days was completely different from recent events. Different field names, different nesting structure. I had to write two separate parsers for what should be the same data.\n\nInterviewer: Tell me about dealing with annual versus monthly billing options.\nParticipant: We wanted to switch from monthly to annual to get the discount, but you can only make that change at the renewal date. I tried to switch mid-cycle and the system told me I had to wait seven more months. There's no option to pay the remaining annual balance and start the annual cycle early. So we're stuck paying the higher monthly rate until October, losing about $200 a month in potential savings. That's $1,400 just thrown away because of an inflexible billing system.\n\nInterviewer: Tell me about a time when you needed to find records matching very specific criteria.\nParticipant: I needed to find all active customers who signed up in Q3 of last year, are on the enterprise plan, and are based in California. That requires filtering on four fields simultaneously. The advanced filter builder lets you add multiple conditions, but there's no way to preview how many results each condition narrows it to. I kept running the query, getting too many results, adding another filter, running again. Each query took about ten seconds. After five iterations of narrowing down, I finally got my list of 23 accounts. The whole thing took about eight minutes.\n\nInterviewer: Walk me through how you typically look things up when you need to find something quickly.\nParticipant: I usually start with the global lookup bar at the top and type whatever I remember. The problem is it only looks at account names by default. If I'm looking for something based on an email address, a phone number, or a custom field, I have to switch to the advanced mode which loads a completely separate page. The advanced page takes about four seconds to load, then I pick which entity type I'm looking for, then which field, then type my query. Four steps for what Google does in one step. My team and I have actually started keeping a Google Sheet with frequently accessed records and their IDs because it's faster.\n\nInterviewer: Tell me about a time when you needed to update your payment method or switch billing contacts.\nParticipant: When our CFO changed, I needed to update the billing email and the credit card on file. Updating the email was simple enough, but changing the payment card required re-entering our full company address, tax ID, and re-verifying our organization. The verification process took 48 hours during which our account was in a limited state and my team couldn't access premium features. That was completely unacceptable for a payment method change.\n\nInterviewer: Walk me through how your engineering team typically [inaudible 00:05:23] authenticates when making calls to external services.\nParticipant: We use bearer tokens for most things. The token generation is straightforward but the tokens expire every four hours with no refresh token mechanism. So our production services have a cron job that generates a new token every three and a half hours and stores it in our secrets manager. If that cron job fails, everything downstream breaks. We've had three outages in the last six months because of token expiration. Every other service we use has refresh tokens or longer-lived service account credentials.\n",
    "duration_minutes": 46,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-039",
    "date": "2024-04-15T20:42:44",
    "participant_id": "P-049",
    "participant_role": "CS Manager",
    "participant_company_size": "1000+",
    "interviewer": "Laura Martinez",
    "interview_type": "behavioral",
    "product_areas_discussed": [
      "notifications"
    ],
    "transcript": "Interviewer: Walk me through how you currently manage which alerts you receive and through which channels.\nParticipant: It's a mess honestly. There are three different places where notifications are configured. There's a global setting under my profile, a per-project setting inside each project, and then individual modules have their own alert toggles. These three layers don't always agree. I once turned off email alerts globally but was still getting them because the project-level setting overrode my global preference. There's no single view that shows me all my active alert subscriptions across everything.\n\nInterviewer: Can you describe a time when alert fatigue led to a real consequence for your team?\nParticipant: Last September our CI/CD pipeline started sending failure alerts for a flaky test that failed about twelve times a day. After a week, the whole engineering team started ignoring pipeline failure emails. Then a legitimate deployment failure happened that introduced a data corruption bug. Nobody caught it from the alerts because we were all so desensitized. The bug was in production for three days before a customer reported data inconsistencies. We estimate it affected about 2,000 records. The root cause wasn't the bug itself, it was the fact that we couldn't distinguish important failures from noise.\n\nInterviewer: Tell me about configuring quiet hours or do-not-disturb for non-critical alerts.\nParticipant: There's no quiet hours feature. Period. I get the same volume of non-critical emails at 3 AM as I do at 3 PM. My phone buzzes with push notifications during dinner, during weekends, during vacation. The only option is to completely mute everything, which means I'd also miss critical alerts. I've asked for a simple quiet hours setting where only severity-one alerts come through between 10 PM and 7 AM. The response was that they're working on notification tiers but no timeline was given. That was over a year ago.\n\nInterviewer: Can you describe a specific situation where you were overwhelmed by too many automated messages?\nParticipant: After we launched a new feature, I started getting an email for every single user action within that feature. I'm talking 300 emails a day. There was no digest option, no frequency cap. I tried to turn off just the activity emails but the only toggle was all-or-nothing for the entire feature module. If I turned it off, I'd also lose critical error alerts. So for two weeks I was getting 300 emails a day until the engineering team pushed an update to add more granular controls. My inbox is still recovering.\n\nInterviewer: Walk me through what happens when you get an email from the system - do you usually act on it or ignore it?\nParticipant: I'd say I act on maybe 10% of the emails I get from the platform. The problem is signal-to-noise ratio. I get about forty system emails a day and maybe four of them require action. The subject lines are all the same format so I can't visually scan for important ones. They all say something like 'Notification from Platform - Event Update.' No severity level, no category, no preview of what happened. I've set up Gmail filters to try to sort them but the email format doesn't give me enough metadata to filter effectively.\n",
    "duration_minutes": 32,
    "recording_quality": "good"
  },
  {
    "interview_id": "INT-040",
    "date": "08/08/2024",
    "participant_id": "P-030",
    "participant_role": "UX Designer",
    "participant_company_size": "1-50",
    "interviewer": "David Kim",
    "interview_type": "discovery",
    "product_areas_discussed": [],
    "transcript": "[00:00:43] David Kim: Can you describe the most frustrating experience you've had trying to get accurate numbers out of the system?\n[00:03:46] Participant: The worst was during our annual planning cycle last November. I needed year-over-year growth numbers broken down by region. The system kept timing out when I tried to pull twelve months of data with the geographic breakdown. When it finally did run, some regions showed negative numbers which made no sense. I pulled the same data set four different ways and got four different answers. Eventually our data engineer had to write a raw query against the database to get the real numbers.\n\n[00:05:09] David Kim: Tell me about the last time you needed to pull data for a stakeholder presentation.\n[00:07:54] Participant: Oh, that was just last week actually. I needed to put together our quarterly metrics for the board meeting. I spent about three hours trying to get the numbers to line up between what I was seeing on screen and what came out in the export. The PDF kept cutting off the right side of the charts, and when I switched to CSV the date columns were all reformatted. I ended up screenshotting everything which felt really hacky for a board presentation.\n\n[00:10:42] David Kim: Walk me through a time when you needed to combine data from multiple views into a single deliverable.\n[00:11:22] Participant: Last quarter I had to merge our product usage data with our customer satisfaction scores for an executive briefing. The usage data was in one section and the satisfaction data was in a completely different module. There's no cross-module summary view, so I exported both as CSVs, opened them in Excel, did a VLOOKUP on account ID, and built my own combined view. The whole thing took half a day when it really should have been a five-minute operation.\n\n[00:16:01] David Kim: Can you describe a specific situation where the numbers you exported didn't match what you expected?\n[00:17:36] Participant: Yes, this happened in January. Our finance team flagged that the revenue figures I sent them were about 12% lower than what they had in their own system. It turned out the date filter was using UTC but I was looking at data assuming Pacific time. So I was missing almost a full day of transactions on either end. Nobody ever told me the system defaults to UTC. That was a really uncomfortable conversation to have with the CFO.\n\n[00:22:23] David Kim: Tell me about how you share periodic summaries with leadership and what that process looks like.\n[00:23:47] Participant: It's honestly more manual than it should be. I generate the summary, export it as a PDF, then paste key highlights into a Slack message. Our VP wants the actual attachment in email though, so I also have to send it via email separately. If I could just set it to auto-send to a Slack channel and an email distribution list at the same time, that would save me probably forty-five minutes a week across all the different summaries I manage.\n\n[00:25:12] David Kim: Can you describe a time when you needed to grant someone access to specific data summaries without exposing everything?\n[00:27:40] Participant: We had a board observer who needed to see our top-line growth metrics but absolutely should not have access to individual customer data or revenue breakdowns by segment. There was no way to share just a specific set of charts. It was all or nothing. I ended up creating a separate login with restricted permissions, but even then some of the drill-down links on the charts would take them to pages they weren't supposed to see. It felt really insecure and I flagged it with our security team.\n",
    "duration_minutes": 25,
    "recording_quality": "fair"
  }
]