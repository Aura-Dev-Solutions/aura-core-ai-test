# ========================================================================
# AURA DOCUMENT ANALYZER - TECHNICAL ASSESSMENT CONFIGURATION
# ========================================================================
# 
#  QUICK START FOR EVALUATORS (DOCKER - RECOMMENDED):
# 1. git clone <repository>
# 2. cd aura-core-ai-test
# 3. docker-compose up -d
# 4. Wait 2-3 minutes for models to download (first run only)
# 5. Access: http://localhost:8000/docs (Swagger UI)
# 6. Test API: http://localhost:8000/health
#
#  ALTERNATIVE (LOCAL DEVELOPMENT):
# 1. cp .env.example .env
# 2. make setup-dev
# 3. make run-dev
#
# ========================================================================

# Application Settings
ENVIRONMENT=development                    # Options: development, production, testing
DEBUG=true                                # Enable debug mode for detailed error messages
SECRET_KEY=change-this-in-production      # JWT secret key (use strong key in production)
LOG_LEVEL=INFO                           # Options: DEBUG, INFO, WARNING, ERROR
LOG_FORMAT=json                          # Options: json, text

# API Configuration
API_HOST=0.0.0.0                         # Host to bind the API server
API_PORT=8000                            # Port for the API server
API_PREFIX=/api/v1                       # API version prefix
CORS_ORIGINS=http://localhost:3000,http://localhost:8080  # Allowed CORS origins

# Database Configuration
# For Docker: Use PostgreSQL container
DATABASE_URL=postgresql+asyncpg://postgres:postgres@postgres:5432/aura_docs
# For local development: Use SQLite
# DATABASE_URL=sqlite+aiosqlite:///./data/aura_demo.db
DATABASE_ECHO=false                      # Set to true to see SQL queries in logs

# Redis Configuration
REDIS_URL=redis://redis:6379/0           # Redis connection (Docker service name)
CACHE_TTL=3600                           # Cache time-to-live in seconds

# File Upload Configuration
UPLOAD_DIR=/app/data/uploads             # Directory for uploaded files (Docker path)
MAX_FILE_SIZE=52428800                   # Maximum file size (50MB)
ALLOWED_EXTENSIONS=.pdf,.docx,.json,.txt # Supported file formats

# AI Models Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2  # Sentence transformer model
EMBEDDING_DIMENSION=384                   # Embedding vector dimension
CLASSIFICATION_MODEL=distilbert-base-uncased            # Text classification model
NER_MODEL=en_core_web_sm                 # spaCy NER model

# Vector Database Configuration
VECTOR_DB_PATH=/app/data/vector_db       # Path for vector database storage (Docker path)
SIMILARITY_THRESHOLD=0.7                 # Minimum similarity for search results
MAX_SEARCH_RESULTS=10                    # Maximum number of search results

# Processing Configuration
MAX_WORKERS=2                            # Maximum concurrent workers (optimized for Docker)
BATCH_SIZE=16                            # Batch size for processing
CHUNK_SIZE=500                           # Text chunk size for processing
CHUNK_OVERLAP=100                        # Overlap between text chunks

# Monitoring Configuration
ENABLE_METRICS=true                      # Enable Prometheus-style metrics
METRICS_PORT=9090                        # Port for metrics endpoint

# Security Configuration
ACCESS_TOKEN_EXPIRE_MINUTES=60           # JWT token expiration time

# Demo Configuration
DEMO_MODE=true                           # Enable demo features
AUTO_LOAD_SAMPLE_DATA=true              # Load sample documents on startup

# ========================================================================
#  EVALUATION CHECKLIST FOR REVIEWERS:
# 
#  BASIC FUNCTIONALITY:
# - Health check: GET http://localhost:8000/health
# - API docs: http://localhost:8000/docs
# - Upload document: POST /api/v1/documents/upload
# - List documents: GET /api/v1/documents/
# 
#  AI FEATURES:
# - Semantic search: POST /api/v1/search/semantic
# - Document classification: POST /api/v1/documents/classify
# - NER extraction: POST /api/v1/documents/{id}/entities
# 
#  PERFORMANCE:
# - Metrics endpoint: GET /metrics
# - Concurrent uploads: Test with multiple files
# - Response times: Should be <500ms for most operations
# 
#  ARCHITECTURE:
# - Docker containers: app, postgres, redis
# - Async processing throughout
# - Proper error handling and logging
# - Clean code structure in src/
#
#  DOCKER SERVICES:
# - app: Main FastAPI application (port 8000)
# - postgres: PostgreSQL database (port 5432)
# - redis: Redis cache (port 6379)
#
#  SAMPLE DATA:
# - Sample documents in data/demo_docs/
# - Test files automatically loaded on startup
# - Ready-to-use API endpoints with sample data
#
#  TROUBLESHOOTING:
# - Check logs: docker-compose logs -f app
# - Restart services: docker-compose restart
# - Clean restart: docker-compose down && docker-compose up -d
# - Check health: curl http://localhost:8000/health
# ========================================================================
