# Documentación de Machine Learning

Esta parte explica cómo está generada la capa de ML y por qué se eligieron estos enfoques.

---

## Visión general

Toda la lógica de IA vive en `app/ml/` y está separada en tres archivos:

- `embeddings.py` → generación de embeddings.
- `classifier.py` → clasificación por tema.
- `ner.py` → Named Entity Recognition (NER).

---

## Embeddings (`app/ml/embeddings.py`)

### ¿Qué hace?

Convierte texto en un vector de números (embedding).  
Eso permite comparar documentos y queries por “significado”, no solo por palabras exactas.

### Modelo usado

- Librería: `sentence-transformers`
- Modelo: `sentence-transformers/all-MiniLM-L6-v2`

### ¿Por qué este modelo?

- Es ligero y rápido, ideal para un sistema que puede procesar muchos documentos.
- Es un estándar para búsqueda semántica en aplicaciones reales.
- Tiene buena calidad para representar frases y textos cortos o medianos (estructurados).

### Uso en el sistema

- Se genera un embedding para:
  - Cada documento procesado (texto extraído).
  - Cada query de búsqueda (`/search`).

El vector se guarda en la BD dentro de la columna `embeddings`, y como mejora, se podría integrar con una base de datos de vectores.

---

## NER (`app/ml/ner.py`)

### ¿Qué hace?

NER (Named Entity Recognition) se encarga de detectar entidades dentro del texto, como:

- Personas
- Organizaciones
- Lugares
- Fechas
- Otros tipos de entidades según el modelo

### Modelo usado

- Librería: `spaCy`
- Modelo por defecto: `en_core_web_sm`

### ¿Por qué spaCy?

- La finalidad de utilizar spaCy es que ya cuenta con modelos entrenados y ahorra tiempo, sin embargo, tiene la flexibilidad de permitirnos entrenar uno desde cero en caso de que sea necesario. 

### Formato de salida

El NER regresa algo como:

```json
{
  "entities": [
    {
      "text": "Mexico",
      "label": "GPE",
      "start_char": 10,
      "end_char": 16
    }
  ]
}
```

En un escenario real, se puede cambiar `NER_MODEL_NAME` en las variables de entorno para usar un modelo entrenado específicamente para el tipo de documento que se requiera.

---

## Clasificación de documentos (`app/ml/classifier.py`)

### ¿Qué hace?

Asigna a cada documento un tema general, por ejemplo:

- politics
- economy
- technology
- sports
- science
- entertainment
- other

### Cómo funciona (idea general)

1. Para cada categoría se define una frase descriptiva en lenguaje natural.
2. Se genera un embedding de esa descripción usando el mismo modelo de embeddings.
3. Para cada documento:
   - Se combina el título con el contenido.
   - Se genera un embedding del documento.
4. Se calcula la **similitud de coseno** entre el embedding del documento y el de cada categoría.
5. La categoría con mayor similitud es la que se toma como resultado.

### ¿Por qué este enfoque?

- Es bastante escalable: solo hay que agregar nuevas categorías y descripciones.
- Considerando que es un modelo ya entrenado, podríamos generar uno desde cero según las necesidades para tener mejores resultados.

### Ejemplo de salida

```json
{
  "category": "technology",
  "confidence": 0.84,
  "candidates": [
    { "category": "technology", "score": 0.84 },
    { "category": "science", "score": 0.70 }
  ],
  "strategy": "semantic_category_similarity"
}
```

---

## Variables de entorno relacionadas con ML

En `.env` se pueden configurar estos valores:

```env
NER_MODEL_NAME=en_core_web_sm
EMBEDDINGS_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
```

- `NER_MODEL_NAME`: nombre del modelo spaCy a cargar.
- `EMBEDDINGS_MODEL_NAME`: modelo de Sentence-Transformers.
